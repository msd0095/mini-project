{"id": "doc0_chunk0", "text": "Tech Legal Insights\n2025. 07\nAID (Artificial Intelligence Decoding) V ol. 6\nRelated Areas\nAI 의료기기\n의료보험시장\nContact\n구태언변호사\nT. 02-3477-8695\nE. tekoo@law-lin.com\n식약처는2025년 5월 7일자로‘인공지능기술이적용된디지털의료기기의허가·심사가\n이드라인’을제정하였습니다. 이미2022년5월에‘인공지능의료기기의허가·심사가이드\n라인’ 이 나왔지만2025년부터디지털의료제품법이의료기기법의특별법으로시행되고\n있기때문에그에맞춰기술변화등을반영, 새롭게제정된것입니다. 법적구속력이없는\n문서이지만의료기기의허가·심사부처인식약처는인공지능기반의디지털의료기기시\n장이발전하고있는추세에맞춰2025년 1월, ‘생성형인공지능의료기기허가·심사가이\n드라인’을세계최초로만들정도로우리의디지털의료환경이글로벌시장에서앞서나가\n고있음을보여주고있습니다.\n이하에서는AI의료기기를둘러싼주요현안이슈들을살펴보고관련의료보험시장의변\n화또한소개합니다.\n1. AI 의료기기와법적쟁점들\n1-1. 정의문제\n가. 2025년 5월의식약처‘인공지능기술이적용된디지털의료기기의허가·심사가이드라\n인’ 은 2022년 5월에 식약처가‘인공지능의료기기의허가·심사 가이드라인’에서 정의한\n‘기계학습가능 의료기기’(MachineLearning-enabledMedicaldevices; 이하 ‘MLMD’)개념\n을 그대로사용, 기계학습방식으로의료용데이터를학습하고특정패턴을인식하여질\n병을진단예측하거나환자에게적합한맞춤치료법을제공하는기기를대상으로해당\n가이드라인이적용됨을밝히고있습니다.\n방석호미국변호사\nT. 02", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 0}}
{"id": "doc0_chunk1", "text": " 기계학습방식으로의료용데이터를학습하고특정패턴을인식하여질\n병을진단예측하거나환자에게적합한맞춤치료법을제공하는기기를대상으로해당\n가이드라인이적용됨을밝히고있습니다.\n방석호미국변호사\nT. 02-3477-8695\nE. shbang@law-lin.com\n설기석변호사\nT. 02-3477-8695\nE. ksseol@law-lin.com\nAI 의료기기를둘러싼주요쟁점과보험시장의변화\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\nAID Vol. 6\n2\n현행디지털의료제품법은지능정보기술, 로봇기술, 정보통신기술등총리령으로정하는첨단기술이\n적용된의료기기법상의의료기기로‘디지털의료기기’를정의하는기술기반방식을택함에따라MLMD\n는기존의의료영상분석·검출또는진단보조에사용하는의료용소프트웨어와는다르며또한기계학\n습기술을활용하는소프트웨어가법상디지털의료기기에해당되는지의여부는사용목적, 기능및사\n용시인체에미치는잠재적위해성(危害性)등의차이에따라판단된다고설명하고있습니다.\n즉 소프트웨어만으로도디지털의료제품법상의디지털의료기기로분류, 식약처의허가·심사를받아\n야만하는경우가있음을전제로1) 의료용데이터를기반으로의료영상, 체외진단기기로부터나온, 신\n호획득시스템(심전계, 뇌파계등)에서나오는패턴또는신호를분석하여질병의진단·치료·예후관찰\n에필요한임상정보를제공하는소프트웨어, 2) 의료용데이터를기반으로의료정보를분석하여얻은\n임상정보(예: 종양병변크기·위치등)를이용하여환자의질병유무, 상태등", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 1}}
{"id": "doc0_chunk2", "text": "분석하여질병의진단·치료·예후관찰\n에필요한임상정보를제공하는소프트웨어, 2) 의료용데이터를기반으로의료정보를분석하여얻은\n임상정보(예: 종양병변크기·위치등)를이용하여환자의질병유무, 상태등에대한가능성정도를자\n동으로진단·예측, 모니터링하거나치료하는소프트웨어는그런디지털의료기기가될 수 있음을예시\n하고있습니다.\n나.식약처의이러한가이드라인입장은미국식품의약국(FDA)의2022년9월28일,임상의사결정지원\n(ClinicalDecisionSupport,CDS)소프트웨어에대한최종가이드라인내용에서도똑같이확인됩니다. 특\n히 의료전문가(HCP; HealthcareProfessionals)가 사용하는비의료기기(non-device)SW에 대한판별기\n준을구체적으로제시하고있다는점에서우리실무에서도참조가될수있습니다.\n구체적으로1)의료영상, 체외진단기기(IVD)의신호,또는신호획득시스템의패턴이나신호를획득,\n처리또는분석할목적이아닐것, 2) 환자에대한의료정보또는기타의료정보를표시, 분석또는인쇄\n할목적일것, 3) 질병이나상태의예방, 진단또는치료에관해HCP에게권고를지원하거나제공할목\n적일것,4)HCP가소프트웨어가제시하는권고의근거를독립적으로검토할수있도록하여,HCP가개\n별환자에대한임상진단이나치료결정을내릴때주로해당권고에의존하도록의도되지않았을것의\n4가지기준을‘모두’충족하면비로소‘비의료기기SW’로판단되어미국FDA의디지털의료기기규제에\n서제외시키고있습니다.\n실무적으로주목해야할부분은세번째와네번째기준입니다. 즉세번째기준은의료용SW가특정하\n고단일한결과나지시를제공하여HCP의판단을‘대체‘하는것이아니라, 권고(정보/옵션으로정의됨)\n를제공함으로써HCP의판단을‘지원’해야하며, 예측을위해위험확", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 2}}
{"id": "doc0_chunk3", "text": ". 즉세번째기준은의료용SW가특정하\n고단일한결과나지시를제공하여HCP의판단을‘대체‘하는것이아니라, 권고(정보/옵션으로정의됨)\n를제공함으로써HCP의판단을‘지원’해야하며, 예측을위해위험확률, 위험점수또는환자가특정상\n태의‘징후를보일수있다’는제안을제공하는SW의경우특정결과를제공하는것으로간주하여세번\n째기준을충족하지못한다고미국FDA는구체적으로적시하고있습니다. 또한네 번째의기준은HCP\n가SW기반의권고에도달한방법을이해하고자신의판단을적용할수있을만큼충분히투명해야한\n다는것으로서결국의료행위의주체인HCP로 하여금SW활용결과물에‘주로’ 의존하도록해서는안\n되며이 기준을충족하지못하면역으로미국FDA규제를받는의료기기로분류되어진다는의미가됩\n니다.\n이런입장은AI의료기기가의료행위의주체인의사를보조하는도구로기능하여야만한다는의미이고\n우리의현행의료법체계는물론글로벌의료AI의기술수준도반영한결과물이라고할수있습니다.\n1-2. 생성형인공지능의료기기와의사의설명의무\n가. 식약처가2025년1월발표한‘생성형인공지능의료기기허가·심사가이드라인’은기존의기계적학\n습(machinelearning)기반의AI모델과달리방대한데이터의패턴기반의확률적추론을통해새로운콘\n텐츠를끊임없이생성하기때문에기존방식으로성능및 임상적유효성을평가하는데 어려움이있음\n을 전제로그러한‘생성형인공지능의료기기’에 대한특성중 하나로‘설명불가능성(inexplicability)을 들\n고있습니다.\n즉생성형의료기기출력값에대한근거(rationale)는잘훈련된임상의와기타의료진도잘이해하지못\n하는생성형AI자체의기술적특성이라는점을지적한것입니다.\n문제는의료행위의주체인의료인은의료법상설명의무를부담하고있고전통적으로의료과오소송\n(medicalmal", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 3}}
{"id": "doc0_chunk4", "text": "된임상의와기타의료진도잘이해하지못\n하는생성형AI자체의기술적특성이라는점을지적한것입니다.\n문제는의료행위의주체인의료인은의료법상설명의무를부담하고있고전통적으로의료과오소송\n(medicalmalpractice)에서중요한쟁점이라는점입니다.\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n3\nAID Vol. 6\n나.구체적으로의료법제24조의2는의료인이환자에게치료방법과위험을설명할의무를규정하고있\n고대법원은“환자가인공지능을활용한의료행위에응할것인지를합리적으로결정할수있도록의사\n의 설명의무는의료행위가행해질때까지적절한시간적여유를두고이행되어야하며, 환자에게충분\n한숙고와상의의시간을제공해야한다”고상세하게판결하고있습니다.(대법원2022.1.27.선고2021\n다265010판결)\n예를들어, 폐질환병변판독을생성형의료기기가한뒤이를바탕으로수술여부를의사가결정, 설명\n의무를이행한다고할때의사는의료법에따라환자에게‘수술등의필요성,방법및내용’을설명하여야\n만하기때문에논리적으로는질병관련사항은물론이고생성형의료기기의역할, 신뢰성과한계등도\n설명하여야만환자는‘충분한숙고와상의의시간’을확보할수있다는결론이되지만정작AI기반진단\n이나치료과정은알고리즘의복잡성등으로인해의사가현실적으로이를완전히이해하거나설명하는\n것이힘들다는점입니다.\n다. 의사의설명의무는불법행위법상‘주의의무’(dutyofcare)를 구체화한것이기때문에생성형AI의료\n기기를사용하여수술필요성여부를최종판단한의사는의료행위주체로서의판단근", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 4}}
{"id": "doc0_chunk5", "text": "힘들다는점입니다.\n다. 의사의설명의무는불법행위법상‘주의의무’(dutyofcare)를 구체화한것이기때문에생성형AI의료\n기기를사용하여수술필요성여부를최종판단한의사는의료행위주체로서의판단근거, AI의료기기\n의신뢰성,한계등을설명할수있으면(explainable)족한것이지AI의료기기의판단근거에대한설명까\n지할(interpretable)필요는없다고해석됩니다.\n즉AI의작동과정에대한BlackBox부분은AI의료기기사용에따른신뢰성,한계등에대한기술적쟁점\n일뿐의사의법적설명의무와는무관한것으로볼수있습니다.\n1-3.의료기기법상의‘위험등급’체계와허가·심사\n가. 의료기기는EU,미국, 우리나라모두위험(risk)기반의차별적규제를통해제품사용을통제하면서\n안전을확보하는대표적영역이고, 위험(위해성) 분류기준은EU와 우리나라가4단계, 미국FDA는 3단\n계구분을하는등구체적차이를보이고있지만, 대부분의국가들이의료기기에대해서는‘위험기반의\n규제방식’(risk-basedapproach)을공통으로택하고있습니다.\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n4\nAID Vol. 6\n위험등급을정하기위한 첫 단추에해당되는것은 의료기기의‘사용목적’ (intendeduse)이지만AI를\n활용하는디지털의료기기는그 특성상자율적으로데이터의학습, 훈련을하면서진화하기때문에‘사\n용목적’을 통한위험등급관리체제가과연유효한지에대한의문이제기될수 있습니다. 이런점을반\n영, 식약처의2025년 ‘인공", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 5}}
{"id": "doc0_chunk6", "text": "료기기는그 특성상자율적으로데이터의학습, 훈련을하면서진화하기때문에‘사\n용목적’을 통한위험등급관리체제가과연유효한지에대한의문이제기될수 있습니다. 이런점을반\n영, 식약처의2025년 ‘인공지능기술이적용된디지털의료기기의허가·심사가이드라인’ 은 MLMD의 특\n성을반영하여적용된알고리즘(기계학습포함)에 관해 작성한자료를제출하여허가·심사를받도록\n하고있습니다.\n나. AI디지털의료기기제작업체는시장에서의제품경쟁력을유지하기위해데이터학습에따른버전\n업데이트를필수적사항으로생각하게되지만미국FDA는 ‘PredeterminedChangeControlPlan(PCCP)’\n이라는개념을도입, 사전에허가 받은 변경 범위 내의 변경만을인정함으로써제조업계와변경허가\n여부를둘러싸고갈등을빚고있습니다.\n우리의디지털의료제품법제11조는 “디지털의료기기의안전성ㆍ유효성에영향을미치는총리령으\n로 정하는중요한사항이변경된경우에는식품의약품안전처장에게변경허가또는변경인증을받거\n나 변경신고를하도록” 하고, 경미한사항인경우에는식약처장에게보고하도록하고있습니다.\n구체적으로식약처장은고시를통해 1) 디지털의료기기소프트웨어에대해서는가. 사용목적또는\n이와관련된핵심적인성능, 나. 생체신호·의료영상과같은분석대상이나분석기법등 알고리즘(분석\n방법),다. 소프트웨어개발 언어또는운영환경, 라. 법 제14조에따른전자적침해행위로부터의보호\n조치에영향을미치는통신기능등, 마. 사용사양서또는사용자인터페이스의변경중 총괄평가(혹\n은 이와동등이상의평가)를 수반하는변경을핵심적인성능에대한변경으로보고있고, 2) 하드웨어\n의 변경 중 성능 또는 전기·기계적안전에영향을미치지않는 해당 디지털의료기기의외관, 치수, 버\n튼의형태및 위치", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 6}}
{"id": "doc0_chunk7", "text": "의평가)를 수반하는변경을핵심적인성능에대한변경으로보고있고, 2) 하드웨어\n의 변경 중 성능 또는 전기·기계적안전에영향을미치지않는 해당 디지털의료기기의외관, 치수, 버\n튼의형태및 위치, 손잡이등의변경을제외한변경또한 핵심적인성능에대한변경으로폭넓게열\n거함으로써모두식약처장의변경허가를받는대상이되도록운영하고있습니다.\n즉 디지털의료기기에대해서는소프트웨어는물론이고하드웨어부분의사후변경도핵심적인성능\n에 대한변경으로넓게추정, 보수적으로변경허가·심사시스템을시행하고있습니다.\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n5\nAID Vol. 6\n2. 의료로봇과AI\n의료서류를 정리, 보고서를 작성하거나 영상을 합성, 변화함으로써진단의 정확도를 높이거나\n통계적으로유사한 합성데이터를생성해 임상시험, 연구, 환자건강개선등을 지원하거나새로운\n화합물 구조를 생성하여 약물개발을 가속화하는 등 가상공간에서의 AI가 아니라 의료로봇에\n탑재되어활용되어지고있는 AI는 진단시실시간데이터분석과최적의수술경로등의 의사결정, 더\n나아가수술시작업보조, 재활등에초점을맞춰상용화로발전시킨것이기때문에특정작업, 특화된\n데이터와 알고리즘, 복잡한 작업순서 등의 성격상 더 고차원적인기술개발, 또한 이에 상응하는\n복잡한규제가따라오게됩니다.\n특히 진단이나검사가아닌 외과수술에사용되는물리적로봇은FDA가 분류한기술등급에따르면\n현재대부분(세계적으로압도적시장점유율을보이고있는daVinci", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 7}}
{"id": "doc0_chunk8", "text": "이에 상응하는\n복잡한규제가따라오게됩니다.\n특히 진단이나검사가아닌 외과수술에사용되는물리적로봇은FDA가 분류한기술등급에따르면\n현재대부분(세계적으로압도적시장점유율을보이고있는daVinci시스템포함) 레벨1 수준이며(da\nVinci는 의사가조종간을직접 움직이면로봇수술기가이 동작을동시에재현하는마스터-슬레이브\n방식)에 그치고 있고 관절수술 등의 일부에서 활용되는 Mako 시스템의 경우 의사가 로봇 팔을\n작동시키면정해진 범위내의 수술을 로봇이 그대로 실행하는 식의 레벨 2 기술단계에이르고는\n있지만결국 의료현장에서의수술로봇은현재 기술적으로, 또 법적으로인간 의사의‘보조적도구’에\n머물고있다고평가할수 있습니다.\n인간의 신체와 생명을 대상으로 한다는 의료의 특성상 AI를 장착한 로봇이 질병의 진단, 검사,\n환자의 재활 등의 영역을 벗어나 수술 등의 의료행위를자율적으로할 수 있도록 하기 위해서는\n법적으로만볼 때 향후 현 의료법체계는물론이고수술로봇에법인격을부여할 것인지의근본적\n문제부터검토가필요하다고할 수 있습니다.\n3. 의료보험시장의변화\n3-1. AI가 의료기기, 데이터처리등에 접목, 확산되어짐에따라 보험상품설계시 예상할 수 없었고\n따라서대처할수 없게된 새로운위험에대비한복합보험상품도등장하고있지만(InsurTech보험사로\n알려진 Relm보험사가올 1월 출시한 PONTAAI상품이 대표적) 의료보험시장에서도관련 특화된\n상품들이속속등장하고있습니다. 다만2024년8월부터시행되고있는EUAI법이진단,진료에서의\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 8}}
{"id": "doc0_chunk9", "text": "부터시행되고있는EUAI법이진단,진료에서의\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n6\nAID Vol. 6\n의사결정등 의료분야에서의AI활용을고위험(high-risk)영역으로간주하면서위험관리시스템을활성\n화하여야만하고,고품질의데이터관리체제와이용자에대한정보제공의투명성과정확성,인간에의한\n감시체제등을의무화하고있으며, 이런의무이행의최종시한이늦어도EUAI법시행후2년내인내년\n8월까지로정해져있습니다.\n보험사기를탐지하고,가입자의신용평가,행동패턴분석등에도물론AI는활용되어질수있지만,특히\n비용절감차원에서보험사가관심을가지게되는‘보험가입자의행동패턴을AI가분석해사기가능성을\n측정’하는행위는고위험AI로분류되어엄격한규제를받기때문에현재까지대체로는개인맞춤형보\n험상품개발및 제공, 개인건강정보기반의위험평가와보험료할인, 환급내지기존의료과실책임보험\n(medicalmalpracticeinsurance)약관에서AI관련특정위험을추가하거나면책하는등의특약을첨가하거\n나 기술수준을고려하여‘의사의최종검토’ 프로세스를중요하게강조하는것 정도가의료보험상품의\n대체적변화모습이라고할수있습니다.\n물론AI가빨리확산되고있는AI의료기기제조사및개발사를대상으로하는새로운관련보험상품도\n경쟁적으로개발되고있고의료기관이보유한민감한환자의료정보를AI를 활용하여처리, 진단, 수술\n등에활용함에따른사이버책임보험상품도등장하고있습니다. 또한Anthem,Aetna등미국의대형보\n험사들이웨어러블데이터,전자건", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 9}}
{"id": "doc0_chunk10", "text": "기관이보유한민감한환자의료정보를AI를 활용하여처리, 진단, 수술\n등에활용함에따른사이버책임보험상품도등장하고있습니다. 또한Anthem,Aetna등미국의대형보\n험사들이웨어러블데이터,전자건강기록,생활패턴데이터등을AI로분석해개인별위험도를정확히평\n가,건강한생활을지속하는가입자에게는보험료할인혜택을제공하고있으며,AI챗봇이1차건강상담\n을제공하고필요시의료진과연결하여주는서비스가포함된영국의BabylonHealth사보험상품처럼텔\n레메디슨과연계된보험상품들도시장에서판매되고는있습니다.\n3-2. 현대적사회보장제도의일환으로독일에서19세기말노동자들을위한건강보험제도가처음시작\n된 이래공공보험과민영보험의역할분담을둘러싼기여비중의차이는있을지언정‘진료이후의비용\n부담을사후보전하는방식’을 공통으로각국의의료보험제도는오랫동안운영되어왔습니다. 이에따\n라보험사고와보험요율을결정하기위해과거의데이터를모아보험상품을개발하고판매하여왔었지\n만디지털과AI의영향으로이제의료보험자체가‘사전에예측하고예방하는’(Predict& Prevent)방향으\n로의변화를보이고있습니다.\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n7\nAID Vol. 6\n즉질병이발생하기전에, 치료가시작되기전에거의실시간으로웨어러블건강보조도구등을통해서\n개인의전자건강데이터를체크할수있음은물론식사, 흡연, 음주, 일패턴, 습관등의관련변수까지고\n려한정기적온라인건강진단도간편하게할수 있게되고유전자정보까지활용되어지면서노후의건\n강 관", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 10}}
{"id": "doc0_chunk11", "text": "을통해서\n개인의전자건강데이터를체크할수있음은물론식사, 흡연, 음주, 일패턴, 습관등의관련변수까지고\n려한정기적온라인건강진단도간편하게할수 있게되고유전자정보까지활용되어지면서노후의건\n강 관리또한체계적으로가능하게됨에따라위험을예측하고사전예방하는디지털의료보험시스템\n도입이실제로이뤄지게된것입니다.특히AI의접목으로학습데이터기반의보험가입자별잠재적질병\n가능성, 수술후의후유증, 부작용을예측하는개인맞춤형서비스제공은물론이고분야별관련데이터\n의정밀화를바탕으로약복용여부, 낙상, 만성질병가능성의경고와음식, 운동, 정기검사권고등의다\n양한보험관련서비스개발,제공도현실적으로가능하게되었습니다.\n이런결과는보험가입자는물론이고보험회사에게도비용지출의감소와위험관리의체계화등 공통\n이익을준다는점 때문에개인은물론이고의료기관, 의료데이터를활용하는관련기관등까지이용할\n수있는AI관련종합의료보험내지특화된상품개발로나타나게되고특히민간의료보험시장의변화는\n더욱경쟁적으로나타날것으로전망됩니다.\n보험시장의이러한혁명적변화를가능하게하는대전제는AI를접목하여의료데이터의공유와활용을\n가능하게하는개인디지털건강기록의통합, 관리및활용시스템구축, 활용이고현재진행되고있는우\n리나라의MyHealthway사업, 또한올3월에발효된유럽의EHDS(EuropeanHealthDataSpace)법이그\n런시스템구상의구체적추진예들입니다.(이들내용에대해서는지난AID5호를참조)\n서울특별시 서초구 서초중앙로24길 10,13층, 14층(서초동, 316타워) | Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n8", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 11}}
{"id": "doc0_chunk12", "text": "| Tel: 02-3477-8695 | Fax: 02-3477-8694\nE-mail: lin@law-lin.com | © 2017 LIN. All Rights Reserved.\n8\nAID Vol. 6\n의료과실, 제조물책임, 데이터보호등과같은전통적쟁점외에생성형 AI를이용자가검색과상담의도구로자주사용하게되면서환각 (hallucination)을통해가짜의학정보를생성해내고잘못된진료와처방까지만들어내는등새로운법적이슈도등장하고있습니다 . 반면, MS가6월30일숙련된의사그룹보다 4배높은진단정확도를자랑하는 AI 진단오케스트레이터 ‘MAI-DxO’를공개함으로써의료 AI의또다른혁명적변화를예고하기도했습니다 . <매월발간하는법무법인린 TMT그룹AI산업센터의뉴스레터인 AID에대한질문 , 조언등은 구태언TMT 전문그룹장(tekoo@law-lin.com), 방석호AI 산업센터장(shbang@law-lin.com), 설기석구성원변호사 (ksseol@law-lin.com)에게보내주십시오 .>\n의료과실, 제조물책임, 데이터보호등과같은전통적쟁점외에생성형AI를이용자가검색과상담의도구로자주\n사용하게되면서환각(hallucination)을 통해가짜의학정보를생성해내고잘못된진료와처방까지만들어내는등\n새로운법적이슈도등장하고있습니다. 반면, MS가6월30일숙련된의사그룹보다4배높은진단정확도를\n자랑하는AI 진단오케스트레이터‘MAI-DxO’를 공개함으로써의료AI의또다른혁명적변화를예고하기도했습니다. \n<매월발간하는법무법인린TMT그룹AI산업센터의뉴스레터인AID에대한질문, 조언등은\n구태언TMT 전문그룹장(tekoo@law-lin.com), 방석호AI 산업센터장(shbang@l", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 12}}
{"id": "doc0_chunk13", "text": ". \n<매월발간하는법무법인린TMT그룹AI산업센터의뉴스레터인AID에대한질문, 조언등은\n구태언TMT 전문그룹장(tekoo@law-lin.com), 방석호AI 산업센터장(shbang@law-lin.com), \n설기석구성원변호사(ksseol@law-lin.com)에게보내주십시오.>", "meta": {"source_path": "data/raw/Tech Legal Insights.pdf", "chunk_index": 13}}
{"id": "doc1_chunk0", "text": "比較私法 第29卷 4號(통권 제99호) 2022年 11月 217~251면The Korean Association of Comparative Private Law Vol.29 No.4 November. 2022. pp.217~251https://doi.org/10.22922/jcpl.2022.29.4.217\n 217\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로*1) 박 혜 진**목 차Ⅰ. 들어가며Ⅱ. 인공지능 의료기기의 규제 및 도입 현황 Ⅲ. 인공지능 의료기기 오작동으로 인한 책임 분배Ⅳ. 마치며국문초록인공지능 기술의 발달은 의료를 혁신하고 의료서비스의 질을 향상시킬 것으로 기대되고 있다. 그러나 인공지능 의료기기가 오작동하는 경우에는 의료진의 최선의 의사결정을 방해하거나 환자에게 나쁜 결과를 가져올 위험성이 있다. 이처럼 국민의 생명·건강과 직결되는 인공지능 의료기기를 어떻게 규제할 것인지, 또 인공지능 의료기기로 인하여 발생한 손해에 대한 책임을 누구에게 지울 것인지는 그 자체로도 중요한 문제일 뿐만 아니라 앞으로의 기술발전의 방향과 속도와도 밀접한 관련이 있다. 이 글에서는 인공지능 의료기기의 규제와 관련하여 우리나라와 미국 등의 규제당국이 대응해 온 문제들을 크게 세 단계로 나누어 조망하고, 우리나라에서 대응해야 할 남아있는 문제들을 살펴본다. 또한, 인공지능 의료기기의 오류로 인하여 환자에게 나쁜 결과가 발생한 경우의 책임 문제에 관하여, 의사의 책임뿐만 아니라 의료기관의 책임, 제조업체의 책임, 그리고 보험 및 계약을 통한 위험 이전 가능성, 마지막으로 공동사업", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 0}}
{"id": "doc1_chunk1", "text": "에게 나쁜 결과가 발생한 경우의 책임 문제에 관하여, 의사의 책임뿐만 아니라 의료기관의 책임, 제조업체의 책임, 그리고 보험 및 계약을 통한 위험 이전 가능성, 마지막으로 공동사업책임(common enterprise liability) 또는 기금 등을 통한 특별보상제도의 도입 필요성에 대하여 전반적으로 검토하면서, 앞으로 더욱 깊이 있는 연구나 논의가 필요한 부분을 가늠해 보고자 한다. ❙주제어❙의료 인공지능, 인공지능 의료기기, 의료기기 규제, 의료과오책임, 인폼드 컨센트, 설명의무, 제조물 책임\n * 이 논문은 한양대학교 교내연구지원사업으로 연구되었음(HY-202100000003545)** 법학박사(J.S.D.), 한양대학교 법학전문대학원, 부교수\n\n비교사법 제29권 4호(통권 제99호)\n218\nⅠ. 들어가며10년 전인 2012년, 선 마이크로시스템(Sun Microsystems)의 공동창업자이자 전설적인 벤처투자자인 비노드 코슬라(Vinod Khosla)는 미국 헬스케어 벤처펀드인 록헬스(Rock Health)가 주최한 의료 혁신에 관한 컨퍼런스에서 “기계가 80퍼센트의 의사를 대체하게 될 것”이라고 말해 큰 논란을 불러일으킨 적이 있다.1) 그 후로 인공지능 기술은 빠르게 발전하여 다양한 의료 분야에서 임상 및 연구에 활용되고 있다.2) 인공지능 알고리즘이 마모그램 영상을 보고 유방암의 발병을 영상의학과 전문의보다 더 정확하게 예측하고,3) 날짜와 날씨 정보를 이용하여 심장마비 발병 위험을 예측하기도 하며,4) 입원환자의 전자의무기록 데이터를 5분마다 실시간으로 분석하여 패혈증 쇼크의 징후를 조기에 포", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 1}}
{"id": "doc1_chunk2", "text": " 예측하고,3) 날짜와 날씨 정보를 이용하여 심장마비 발병 위험을 예측하기도 하며,4) 입원환자의 전자의무기록 데이터를 5분마다 실시간으로 분석하여 패혈증 쇼크의 징후를 조기에 포착하기도 한다.5) 인공지능 기술의 발달은 의료 빅데이터에서 새롭고 중요한 정보를 추출함으로써 의료를 혁신하고 의료서비스의 질을 향상시킬 것으로 기대되고 있다.6) 이미 미국의 의료기관의 3분의 1이 환자의 영상 분석 등에 인공지능을 활용하고 있다고 한다.7) 현재 인공지능이 의료에서 활용되는 대표적인 분야는 의료 영상 분석(medical image analysis)과 임상 의사결정 지원(clinical decision support)이다.8) 의료 영상이나 병리학 슬라이드를 분석하여 진단에 도움을 주고, 환자의 의료 기록을 분석하여 의료진에게 알람을 보내거나 예측결과를 제공함으로써 임상 의사결정의 질을 높이고 오류를 줄여주는 역할을 하고 있다.9) 그러나 인공지능 의료기기가 오작동하는 경우에는 의료진의 최선의 의사결정을 방해하거나 환자에게 나쁜 결과를 가져올 위험성이 있다. 이처럼 국민의 생명·건강과 직결되는 인공지능 의1)Liat Clark, Vinod Khosla: Machines will replace 80 percent of doctors, Apr. 9, 2012. Wired, available at: https://www.wired.co.uk/article/doctors-replaced-with-machines.2)보건의료영역에 인공지능은 임상진단, 질병 예측, 영상판독이나 상체분석, 수술로봇, 의학연구, 앱 기반 의료서비", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 2}}
{"id": "doc1_chunk3", "text": "ticle/doctors-replaced-with-machines.2)보건의료영역에 인공지능은 임상진단, 질병 예측, 영상판독이나 상체분석, 수술로봇, 의학연구, 앱 기반 의료서비스, 건강 및 사회복지 자원의 효율적 배분, 공중보건을 위한 조기예측 등에 적용되고 있다. 이인영, “보건의료에서의 인공지능 적용과 관련된 법적 과제에 대한 개관”, 「한국의료법학회지」, 제27권 제2호(2019), 40~44면.3)Jessica Hamzelou, AI system is better than human doctors at predicting breast cancer, New Scientist (Jan. 1, 2020). 4)BMJ, Machine learning (AI) accurately predicts cardiac arrest risk (May 17, 2021), available at https://www.bmj.com/company/newsroom/machine-learning-ai-accurately-predicts-cardiac-arrest-risk/.5)Eliza Strickland, Hospitals Roll out AI systems to Keep Patients From Dying of Sepsis, IEEE Spectrum (Oct. 19, 2018).6)U.S. Food and Drug Admin., Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning Based Software as ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 3}}
{"id": "doc1_chunk4", "text": "egulatory Framework for Modifications to Artificial Intelligence/Machine Learning Based Software as a Medical Device (SaMD) 2 (2019), https://www.fda.gov/media/122535/download.7)Jessica Kent, One Third of Orgs Use A.I. in Med. Imaging, Health IT Analytics (Jan. 28, 2020), https://healthitanalytics.com/news/one-third-of-orgs-use-artificial-intelligence-in-medical-imaging.8) Frank Griffin, Artificial Intelligence and Liability in Health Care, 31 Health Matrix 65, 73-78 (2021).9) Ibid.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 219\n료기기를 어떻게 규제할 것인지(사전적 규제), 또 인공지능 의료기기의 오작동으로 인하여 발생한 손해에 대한 책임을 누구에게 지울 것인지(사후적 규제)의 문제는 그 자체로도 중요한 문제이고, 앞으로의 기술발전의 방향 및 속도와도 밀접한 관련이 있다. 과도한 규제를 하게 되면 자칫 이로 인하여 산업 발전이 저해될 수도 있고, 적절한 규제가 없이는 의사나 환자가 안전의 우려로 최신의 인공지능 의료기기 사용을 꺼리게 될 수도 있기 때문이다. 우선, 인공지능 의", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 4}}
{"id": "doc1_chunk5", "text": " 이로 인하여 산업 발전이 저해될 수도 있고, 적절한 규제가 없이는 의사나 환자가 안전의 우려로 최신의 인공지능 의료기기 사용을 꺼리게 될 수도 있기 때문이다. 우선, 인공지능 의료기기를 어떻게 규제할 것인가(사전적 규제)에 관하여는 기존에 인공지능 소프트웨어를 의료기기로 보아 규제할 수 있는지에 관한 문제를 다루거나10) 인공지능 의료기기 관련 규제 현황을 개괄한 연구11)가 있었다. 이 글에서는 인공지능 의료기기의 규제와 관련하여 우리나라와 미국의 규제당국이 대응해 온 문제들을 크게 규제의 진화의 3단계로 나누어 살펴보고,12) 우리가 대응해야 할 남아있는 문제들을 짚어 본다. 다음으로, 인공지능 의료기기의 오류와 관련한 민사책임 문제(사후적 규제)에 관하여는, 주로 의사의 책임과 관련하여 논의가 이루어져 왔을 뿐13) 의료기관이나 제조업체 등 다른 책임주체들의 책임도 함께 검토한 연구는 거의 없었다.14) 이 글에서는 의사의 책임뿐만 아니라 의료기관의 책임, 제조업체의 책임, 그리고 보험 및 계약을 통한 위험 이전 가능성, 마지막으로 공동사업책임(common enterprise liability) 또는 기금 등을 통한 특별보상제도의 도입 필요성에 대하여 전반적으로 검토하면서, 인공지능 의료기기와 관련된 책임에 관한 논의의 외연을 확장하고, 앞으로 더욱 깊이 있는 연구 및 토론이 필요한 부분을 가늠해 보고자 한다. 다만 이 글에서는 의료 빅데이터를 둘러싼 개인정보 보호 등의 문제와 인공지능 의료기기 활용과 관련한 형사책임에 관한 문제는 직접적으로 다루지 않는다.우선, 아래에서는(II.) 인공지능 의료기기가", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 5}}
{"id": "doc1_chunk6", "text": "는 의료 빅데이터를 둘러싼 개인정보 보호 등의 문제와 인공지능 의료기기 활용과 관련한 형사책임에 관한 문제는 직접적으로 다루지 않는다.우선, 아래에서는(II.) 인공지능 의료기기가 어떻게 규제되고 있고, 얼마나 시장에 나오고 있는10)김재선, “인공지능 의료기기 위험관리를 위한 규범론적 접근-인공지능 소프트웨어 규범화 논의를 중심으로-”, 「공법연구」, 제46집 제2호(2017); 엄주희/김소윤, “인공지능 의료와 법제”, 「한국의료법학회지」, 제28권 제2호(2020).11)김광수, “인공지능 기반 과학기술과 국민의 권익구제-자율주행차, 드론 및 의료기기를 중심으로-”, 「토지공법연구」, 제85집(2019).12)본 논문에서는 지면의 한계상 유럽의 인공지능 의료기기 규제에 대하여는 다루지 않는다. 유럽의 인공지능 의료기기 규제에 관하여는, Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, Regulatory responses to medical machine learning, 7 J. L.& Biosciences 1 (2020) 참조.13)배현아, “보건의료법제 하에서 인공지능기술의 의료영역 도입의 의의와 법적 문제”, 「법조」, 제724집(2017) (본격적으로 인공지능 의료기기가 임상에 도입되기에 앞서 인공지능 의료기기와 관련한 규제법적, 책임법적 이슈를 폭넓게 다루었음); 백경희/장경화, “인공지능을 이용한 의료행위와 민사책임에 관한 고찰”, 「법조」, 제724집(2017) (인공지능 의료기기의 본격적 도입에 앞서 인공지능 의료기", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 6}}
{"id": "doc1_chunk7", "text": "폭넓게 다루었음); 백경희/장경화, “인공지능을 이용한 의료행위와 민사책임에 관한 고찰”, 「법조」, 제724집(2017) (인공지능 의료기기의 본격적 도입에 앞서 인공지능 의료기기를 활용하는 의료행위의 특수성과 인공지능을 활용한 의료행위시 발생할 수 있는 민사책임 문제를 폭넓게 다루었음); 설민수, “머신러닝 인공지능과 인간전문직의 협업의 의미와 법적 쟁점: 의사의 의료과실 책임을 사례로”, 「저스티스」, 제163호(2017) (인간 전문직과 머신러닝 인공지능의 협업이라는 점에 착안하여 인공지능 의료기기를 활용하는 의사의 책임 문제를 다룸); 정채연, “의료 인공지능의 법적 수용을 위한 시론적 연구”, 「법학논총」, 제45권 제3호(2021) (의료 인공지능을 둘러싸고 제기되는 법적, 사회적, 윤리적 쟁점들을 조망함).14)이중기/이재현, “의료 AI에 대한 규제체제와 책임의 귀속-진단AI와 수술로봇을 중심으로-”, 「홍익법학」, 제21권 제4호(2020) (진단 AI와 수술로봇의 이용과 관련하여 책임의 귀속 문제를 다룸).\n\n비교사법 제29권 4호(통권 제99호)\n220\n지에 대한 이해를 돕기 위하여 인공지능 의료기기의 정의 및 규제대상으로서의 특수성, 국내외 규제 이슈 및 아직 해결되지 않은 문제들을 차례로 짚어본다. 그 다음으로(III.), 인공지능 의료기기의 오작동으로 인하여 환자에게 나쁜 결과가 발생한 경우 그 책임을 어떻게 분배할 것인지의 문제에 관하여, 의사의 의료과오책임 및 설명의무위반 책임, 의료기관의 책임, 인공지능 의료기기 제조업자의 책임, 보험 등 위험의 이전 방안 및 공동사업책임 또는", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 7}}
{"id": "doc1_chunk8", "text": "게 분배할 것인지의 문제에 관하여, 의사의 의료과오책임 및 설명의무위반 책임, 의료기관의 책임, 인공지능 의료기기 제조업자의 책임, 보험 등 위험의 이전 방안 및 공동사업책임 또는 기금 등 무과실 보상제도를 살펴본다. 마지막으로(IV.) 앞으로 연구자와 이해관계자들의 관심과 논의가 필요한 부분을 다시 한번 언급하면서 이 글을 끝맺는다. Ⅱ. 인공지능 의료기기의 규제 및 도입 현황1. 인공지능 의료기기의 정의인공지능 의료기기에 대한 본격적인 논의에 앞서 인공지능 의료기기란 무엇을 의미하는지 짚고 넘어갈 필요가 있다. 비록 인공지능의 정의에 대한 논란은 아직 완전히 정리되지 않았지만, 의료기기 규제당국의 자율적 모임인 국제의료기기규제당국자포럼(International Medical Device Regulators Forum, IMDRF)의 인공지능 의료기기 실무 그룹(Artificial Intelligence Medical Device working group)은 최근 용어의 통일을 위하여 인공지능 의료기기 국제 공통 지침안을 발간하였다.15) 따라서 인공지능 의료기기를 다루는 이 글에서는 위 지침안을 기준으로 논의를 진행하기로 한다. 위 지침안에 따르면, 인공지능이란, 알고리즘이나 모델을 이용하여 학습, 의사결정, 및 예측 등을 행하도록 하는 컴퓨터 공학 및 통계학의 한 분야이다.16) 인공지능의 하위분류인 기계학습(Machine Learning, ML)은 컴퓨터 알고리즘이 일일이 프로그래밍하지 않아도 데이터를 학습하여 특정 과제(task)를 수행할 수 있게 하는 기술이다.17) 기계학습(ML)의 하위분류인 딥", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 8}}
{"id": "doc1_chunk9", "text": "arning, ML)은 컴퓨터 알고리즘이 일일이 프로그래밍하지 않아도 데이터를 학습하여 특정 과제(task)를 수행할 수 있게 하는 기술이다.17) 기계학습(ML)의 하위분류인 딥러닝(Deep Learning)은 컴퓨터가 방대한 양의 데이터를 접하면서 스스로 학습하도록 하는 방식으로,18) 최근 컴퓨터 비전(Computer Vision)이나 자연어 처리(Natural Language Processing) 등에서 비약적 기술 발전이 있었던 분야이지만, 다른 한편으로는 가장 불투명성(opacity)이 문제로 지적되는 분야이기도 하다. 기계학습을 이용한 기술은 흔히 인공지능(AI) 또는 인공지능/기계학습(AI/ML)으로 일컬어지기도 하는데, 의료기기에 기계학습 기술을 접목시킨 의료기기, 즉 기계학습 15)IMDRF AIMD Working Group, Machine Learning-enabled Medical Devices—A Subset of Artificial Intelligence-enabled Medical Devices: Key Terms and Definitions, 16 September 2021.16)Ibid., p.4 (“a branch of computer science, statistics, and engineering that uses algorithms or models to perform tasks and exhibit behaviors such as learning, making decisions and making predictions”).17)위의 글 (“a subset of AI th", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 9}}
{"id": "doc1_chunk10", "text": "it behaviors such as learning, making decisions and making predictions”).17)위의 글 (“a subset of AI that gives computers the ability to learn without being explicitly programmed“).18) 위의 글 (“[a] subset of ML: enable computer to teach itself by exposing it to vast amount of data”).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 221\n의료기기(Machine Learning-enabled Medical Devices, MLMD)는 실제 사용되는 환경에서 경험을 통하여 성능을 향상시킬 수 있다는 것이 가장 큰 장점이다.19) 이 글에서는 좀 더 넓은 개념인 인공지능 의료기기를 다루고 있으나, 규제법적, 책임법적으로 주로 문제가 되는 것은 인공지능 의료기기 중 기계학습 의료기기의 경우가 될 것이다. 2. 규제 대상으로서의 인공지능 의료기기의 특성인공지능 의료기기, 특히 기계학습 의료기기는 여타 소프트웨어 의료기기와 다른 몇 가지 특징을 가지고 있다. 첫 번째 특징은 불투명성(opacity)이다. 인공지능 의료기기에 사용되는 알고리즘이 인풋과 아웃풋 사이에 어떤 관계를 포착하는지 정확히 이해할 수 없고, 설명할 수도 없어 불투명(non-transparent)하다는 점을 들어 인공지능 의료기기를 블랙박스 의료(blackbox medicine)라고 부르기도 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 10}}
{"id": "doc1_chunk11", "text": " 정확히 이해할 수 없고, 설명할 수도 없어 불투명(non-transparent)하다는 점을 들어 인공지능 의료기기를 블랙박스 의료(blackbox medicine)라고 부르기도 한다.20) 특히 뒤에서 보겠지만 이러한 의료기기를 이용하여 의료행위를 하는 경우 의사의 책임과 관련하여도 인공지능 의료기기의 불투명성이 문제가 된다. 두 번째 특징은 적응성(adaptability)으로, 새로운 데이터를 접하면 그에 맞추어 알고리즘이 변화하는 성질을 말한다. 인공지능 의료기기가 잠긴 상태에 있는 경우, 즉 새로운 데이터를 접하여도 알고리즘이 변화하지 않는 의료기기를 “잠긴 의료기기(locked device)”라고 부르고, 새로운 데이터를 접하면서 그 알고리즘이 변화하는 의료기기는 “적응하는 의료기기(adaptive device)”라고 부른다. 바로 이 계속하여 변화하는(continuous learning) 특성 때문에 인공지능 의료기기의 규제가 쉽지 않다.인공지능 의료기기에서 주목해야 할 또 하나의 특징은 잠재적 편향성(bias)이다.21) 이는 대표성이 없는 데이터, 기존의 의료에서의 편향을 반영하는 데이터, 개발자의 편향 등을 이유로 발생할 수 있다. 예컨대, 대표성이 없는 데이터로 훈련된 심근병증 유전자 시험 알고리즘은 백인에 대해 다른 인종에서보다 높은 성능을 보였다.22) 나아가, 대형병원에서 전문가가 진료하는 환경에서 잘 기능하도록 훈련된 알고리즘은 그와 달리 자원이 부족한 환경에서는 적절하고 안전하며 19) 위의 글.20)인공지능 의료기기의 불투명성에 관한 논의로는, W. Nicholson II Pric", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 11}}
{"id": "doc1_chunk12", "text": "록 훈련된 알고리즘은 그와 달리 자원이 부족한 환경에서는 적절하고 안전하며 19) 위의 글.20)인공지능 의료기기의 불투명성에 관한 논의로는, W. Nicholson II Price, Black-Box Medicine, 28 Harv. J. L. & Tech. 419, 421 (2015); W. Nicholson Price II, Regulating Black-Box Medicine, 116 Mich. L. Rev. 421 (2017); Boris Babic et al., Beware Explanation from AI in Healthcare, 373 Science 284 (2021); Boris Babic & Sara Gerke, Explaining Medical AI is Easier Said than Done, Stat, 21 July 2021, available at: https://www.statnews.com/2021/07/21/explainable-medical-ai-easier-said-than-done.21)Griffin, 위의 글, 82~83면 (인공지능이 편향성을 나타낼 수 있는 이유로 특정 인구집단이 과소대표(under-represenation)되는 경우, 대표성을 결여한 데이터 수집, AI가 불공정하게 적용되는 경우, 개발자나 사용자의 편향을 반영하는 경우를 언급함); Ziad Obermeyer et al., Dissecting racial bias in an algorithm used to manage the health of populations, 366 Science 447 (2", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 12}}
{"id": "doc1_chunk13", "text": " Dissecting racial bias in an algorithm used to manage the health of populations, 366 Science 447 (2019). 22)Latrice G. Landry, Heidi L. Rehm, Association of Racial/Ethnic Categories with the Ability of Genetic Tests to Detect a Cause of Cardiomyopathy, 3 JAMA Cardiol 341 (2018).\n\n비교사법 제29권 4호(통권 제99호)\n222\n경제적인 치료법을 추천하지 못할 수 있다는 상황별 편향(‘contextual’ bias)도 문제될 수 있다.23) 편향성 문제는 인공지능 의료기기를 채택하여 이용하는 의사나 의료기관의 책임은 물론 인공지능 의료기기 제조업자의 책임에도 영향을 줄 수 있다.다음에서는 이와 같은 인공지능 의료기기의 특성24)을 고려할 때 인공지능 의료기기를 효과적으로 적절하게 하기 위한 노력을 미국과 우리나라 위주로 살펴본다.3. 인공지능 의료기기의 규제의 진화인공지능 의료기기를 어떻게 규제할 것인지에 관한 논의는 크게 세 단계로 나누어 설명할 수 있다. 우선, 인공지능 의료기기가 주로 소프트웨어의 형태를 띤다는 점에서, 소프트웨어를 의료기기로 포섭하여 엄격한 의료기기에 대한 규제를 적용할 것인지가 문제되었다. 다음으로, 소프트웨어의 특성을 고려하여 기존의 의료기기 규제와 다른 새로운 방식을 고려해야 하는지에 대한 고민이 있었다. 마지막으로, 시판 후에 실제 사용하는 과정에서 새로운 데이터", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 13}}
{"id": "doc1_chunk14", "text": "음으로, 소프트웨어의 특성을 고려하여 기존의 의료기기 규제와 다른 새로운 방식을 고려해야 하는지에 대한 고민이 있었다. 마지막으로, 시판 후에 실제 사용하는 과정에서 새로운 데이터에 맞추어 적응하는(adaptive) 인공지능 의료기기의 경우 적절한 규제 방안이 무엇인지에 대하여 지금도 논의가 진행 중이다.(1) 소프트웨어도 의료기기에 포함되는가?미국에서 의료기기의 안전성을 감독하는 연방 규제기관은 식품의약품안전청(U.S. Food and Drug Administration, FDA)이다. 1938년 연방 식품의약품화장품법(Food, Drug and Cosmetics Act)이 제정되면서 의료기기에 대한 개념이 도입되었으나, 본격적으로 의료기기의 안전관리 제도가 도입된 것은 1976년 의료기기 개정법(The Medical Device Amendments)에서 등급분류 체계와 중저위험도 의료기기에 대한 시판 전 본질적 동등성 평가제도(501(k)) 및 고위험도 의료기기에 대한 시판 전 평가 제도(Premarket approval, PMA)를 도입하면서 부터였다.25) 의료기기를 안전성과 유효성에 대한 우려 정도에 따라 3개의 등급(Class I, Class II, Class III)으로 나누고, 그 등급에 따라 얼마나 엄격한 심사를 거쳐 시판을 허용할 것인지 여부를 결정하게 된다. 1등급(Class I) 의료23) W. Nicholson Price II, Medical AI and Contextual bias, 33 Harv. J.L. & Tech. 65(2019).24)위에서 언급한 특성들 외에도 인공지능 의료", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 14}}
{"id": "doc1_chunk15", "text": " Price II, Medical AI and Contextual bias, 33 Harv. J.L. & Tech. 65(2019).24)위에서 언급한 특성들 외에도 인공지능 의료기기에서 간과하지 않아야 할 측면은 바로 보안(cybersecurity) 문제이다. 인공지능 의료기기는 주요 구성부분이 소프트웨어로서 인터넷이나 센서에 연결된 경우가 많고, 상대적으로 고가에 거래가 가능한 의료 데이터를 다루기에 사이버 공격의 표적이 되기 쉽다. 뿐만 아니라 인공지능 알고리즘에 내재한 취약점을 노리는 적대적 공격(adversarial attack)에 노출될 가능성도 있다. 이 글에서 인공지능 의료기기의 보안 위험에 관한 규제나 책임 문제까지 다루기에는 지면이 부족하나, 이 문제는 인공지능 의료기기, 더 넓게는 소프트웨어 의료기기의 사용 증가와 함께 더 많은 관심이 필요한 이슈임은 분명하다.25)김병관/양석조, “임상적 관점에서의 의료기기 관리제도 개선방안 연구”, 「과학기술법연구」, 제25집 제4호(2019), 10면.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 223\n기기는 비교적 단순하며 오랫동안 안전하게 사용되어 온 것으로서, 압설자(tongue depressor), 팔걸이(arm sling) 등이 이에 해당되고, 통상 시판 전 평가에서 면제된다. 2등급(Class II) 의료기기는 안전성과 유효성에 대한 우려가 1등급 의료기기에 비해 큰 경우로서, 인슐린 펌프, 엑스레이 기계 등이 통상 이에 해당하며, 510(k) 절차라는 비교적 간단한 시판 전 평가 또는 D", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 15}}
{"id": "doc1_chunk16", "text": "전성과 유효성에 대한 우려가 1등급 의료기기에 비해 큰 경우로서, 인슐린 펌프, 엑스레이 기계 등이 통상 이에 해당하며, 510(k) 절차라는 비교적 간단한 시판 전 평가 또는 De Novo classification 절차26)를 거쳐 시장에 나오게 된다. 3등급(Class III) 의료기기는 가장 엄격한 시판 전 허가(Premarket Approval, PMA) 절차를 거치도록 되어 있는데, 생명을 유지하거나, 건강 침해 방지에 중요한 역할을 하는 의료기기, 또는 질병이나 상해의 비합리적인 위험을 야기하는 의료기기, 예컨대 삽입형 제세동기(implantable defibrillator) 같은 경우가 이에 해당한다.27) 위 1976년 법에서는 의료기기를 정의하는 규정을 두고 있는데28) 소프트웨어가 의료기기에 해당하는지 여부가 중요한 이유는, 의료기기로 포섭되는 순간 의료기기에 대한 시판전후(pre-marketing and post-marketing)의 엄격한 규제가 적용되기 때문이다.29) 소프트웨어가 의료 현장에서 이용되는 경우가 빈번해 지면서, 각국의 규제당국들이 의료 목적의 소프트웨어를 어떻게 규제할 것인지에 대해 관심을 가지기 시작했다. 특히 의료목적의 소프트웨어 중 기존에 규제 대상으로 당연히 포함되었던 ‘의료기기의 일부로서의 소프트웨어(Software in a medical device, 이하 SiMD)’, 즉 하드웨어 의료기기의 구성부분 일부를 이루는 소프트웨어 외에도, ‘의료기기로서의 소프트웨어(Software as a medical device, 이하 SaMD)’,30) 즉, 하드웨어 의료", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 16}}
{"id": "doc1_chunk17", "text": " 의료기기의 구성부분 일부를 이루는 소프트웨어 외에도, ‘의료기기로서의 소프트웨어(Software as a medical device, 이하 SaMD)’,30) 즉, 하드웨어 의료기기의 일부를 이루지 않는 의료 목적의 소프트웨어에 대한 효과적 규제가 필요하다는 데 각국 규제당국들이 인식을 같이하였다. 국제의료기기규제당국자포럼(IMDRF)의 SaMD 26)De novo classifiation 절차란 기존에 허가받은 동등한 의료기기(predicate device)가 없는 중저위험의 의료기기에 적용되는 절차로서, 이를 통해 1등급 또는 2등급 의료기기로 분류될 수 있다. FDA, De Novo Classification Request, https://www.fda.gov/medical-devices/premarket-submissions-selecting-and-preparing-correct-submission/de-novo-classification-request.27)의료기기의 분류와 시판전 절차에 대하여는, FDA, How to Study and Market Your Device, https://www.fda.gov/medical-devices/device-advice-comprehensive-regulatory-assistance/how-study-and-market-your-device.28)Food, Drug, and Cosmetics Act (FDCA) Section 201(h)(“An instrument, apparatus, implement, machine, contrivance, implant", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 17}}
{"id": "doc1_chunk18", "text": "metics Act (FDCA) Section 201(h)(“An instrument, apparatus, implement, machine, contrivance, implant, in vitro reagent, or other similar or related article, including a component part, or accessory which is: 1. recognized in the official National Formulary, or the United States Pharmacopoeia, or any supplement to them, 2. intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, or prevention of disease, in man or other animals, or 3. intended to affect the structure or any function of the body of man or other animals, and which does not achieve its primary intended purposes through chemical action within or on the body of man or other animals and which does not achieve its primary intended purposes through chemical action within or on the bod", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 18}}
{"id": "doc1_chunk19", "text": "nd which does not achieve its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of its primary intended purposes. The term \"device\" does not include software functions excluded pursuant to section 520(0)”).29)Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, Regulatory responses to medical machine learning, 7 J. L.& Biosciences 1, 4-5 (2020) 참조.30)FDA, Software as a Medical Device, https://www.fda.gov/medical-devices/digital-health/software-medical-device-samd.\n\n비교사법 제29권 4호(통권 제99호)\n224\n실무그룹에서는 2013년부터 미국 식품의약품안전청(FDA)이 주축이 되어 SaMD에 대한 규제에 관한 일련의 가이드라인을 마련하였다.31)미국은 2015년 21세기 치료법(21st Century Cures Act)을 제정하여 식품의약품화장품법(FDCA)에서 정하는 의료기기에 포함되는 소프트웨어의 범위를 보다", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 19}}
{"id": "doc1_chunk20", "text": "다.31)미국은 2015년 21세기 치료법(21st Century Cures Act)을 제정하여 식품의약품화장품법(FDCA)에서 정하는 의료기기에 포함되는 소프트웨어의 범위를 보다 명확히 하였다. 위 법은 행정적 기능을 지원하는 소프트웨어, 건강한 라이프스타일을 장려하는 소프트웨어, 전자의무기록을 관리하는 소프트웨어, 데이터를 전송·저장·변환하는 소프트웨어, 그리고 일정한 조건을 만족하는 임상 의사결정 지원(clinical decision support) 소프트웨어를 규제 대상에서 제외하였다.32) 또한 미국 식품의약품안전청(FDA)은 가이드라인을 통해 현재로서는 심각한 의료 상황에 적용되는 임상 의사결정 보조 소프트웨어만을 규제하겠다는 입장을 명확히 밝혔다.33)우리나라에서도 2003년 의료기기법이 제정된 이래 의료기기의 시판 전 및 시판 후 단계에서의 안전성·유효성의 관리가 이루어져왔는데, 2018년에 기술발전과 국제적 기준을 반영하여 의료기기법 제2조 의료기기의 정의에 소프트웨어를 명시적으로 추가하였다.34) 뿐만 아니라 그에 앞선 2017년에는 식약처가 세계 최초로 「의료용 빅데이터와 인공지능(AI) 기술이 적용된 의료기기의 허가·심사 가이드라인」을 마련하여 의료용 소프트웨어가 의료기기에 해당하는지 여부는 사용목적과 위해도를 고려하여 종합적으로 판단한다고 밝히고, 의료기기에 해당하는 소프트웨어의 범위를 구체적으로 제시하였다.35) 예컨대 의료용 빅데이터를 기반으로 의료영상, 체외진단기기로부터 나온 시그널, 신호 획득시스템(심전계, 뇌파계 등)에서 나오는 패턴 또는 시그널을 분석하여 진단·치료에 필요한 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 20}}
{"id": "doc1_chunk21", "text": "5) 예컨대 의료용 빅데이터를 기반으로 의료영상, 체외진단기기로부터 나온 시그널, 신호 획득시스템(심전계, 뇌파계 등)에서 나오는 패턴 또는 시그널을 분석하여 진단·치료에 필요한 임상정보를 제공하는 소프트웨어는 의료기기에 해당하나, 의료기관의 행정사무(병실·재고관리, 전자수속 등)를 지원하는 소프트웨어나 운동·레저 및 일상적인 건강관리 31)IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Key Definitions (2013); IMDRF SaMD Working Group, \"Software as a Medical Device\": Possible Framework for Risk Categorization and Corresponding Considerations (2014); IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Application of Quality Management System (2015); IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Clinical Evaluation (2017).32) 21st Century Cures ACt, sec. 3060.33)FDA, General Wellness: Policy for Low Risk Devices, Guidance for Industry and Food and Drug Administration Staff, https://www.fda.gov/me", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 21}}
{"id": "doc1_chunk22", "text": "w Risk Devices, Guidance for Industry and Food and Drug Administration Staff, https://www.fda.gov/media/90652/download.34) 의료기기법 제2조(정의) ① 이 법에서 \"의료기기\"란 사람이나 동물에게 단독 또는 조합하여 사용되는 기구 · 기계 · 장치 · 재료 · 소프트웨어 또는  이와 유사한 제품으로서 다음 각 호의 어느 하나에 해당하는 제품을 말한다. 다만, 「약사법」에 따른 의약품과 의약외품 및  「장애 인복지법」 제65조에 따른 장애인보조기구 중 의지(義肢)·보조기(補助器)는 제외한다. 1. 질병을 진단·치료·경감·처치 또는 예방할 목적으로 사용되는 제품2. 상해(傷害) 또는 장애를 진단·치료 · 경감 또는 보정할 목적으로 사용되는 제품3. 구조 또는 기능을 검사 · 대체 또는 변형할 목적으로 사용되는 제품4. 임신을 조절할 목적으로 사용되는 제품35)식품의약품안전처, 빅데이터 및 인공지능(AI) 기술이 적용된 의료기기의 허가·심사 가이드라인(민원인 안내서), 2017.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 225\n목적의 소프트웨어는 의료기기에 해당하지 않는다.36) 우리나라의 경우 의료기기에 해당하게 되면 사용목적과 인체에 미치는 잠재적 위해도에 따라 품목별로 4등급으로 분류하고37) 등급에 따라 요구되는 인허가절차가 개괄적으로 정해진다.38) 1등급 의료기기는 대개 신고 대상이고, 2등급 의료기기는 의료기기안전정보원의 인증을 받아야 하며, 3등급 및 4", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 22}}
{"id": "doc1_chunk23", "text": "37) 등급에 따라 요구되는 인허가절차가 개괄적으로 정해진다.38) 1등급 의료기기는 대개 신고 대상이고, 2등급 의료기기는 의료기기안전정보원의 인증을 받아야 하며, 3등급 및 4등급 의료기기는 식약처의 허가를 받아야 한다. 다만 이미 인허가를 받은 의료기기와 구조·원리·성능·사용목적 등이 본질적으로 동등하지 않은 의료기기의 경우 시판 전 단계에서 허가를 받기 위한 임상자료 평가를 거쳐야 한다.39)(2) 소프트웨어에 적합한 규제는 어떠해야 하는가?이처럼 미국의 규제당국은 일정한 의료목적의 소프트웨어를 의료기기로 보아 규제하기로 하였으나, 기존의 하드웨어 중심의 전통적 규제방식이 소프트웨어 의료기기에는 적합하지 않다는 문제가 대두되었다. 새로이 개발된 소프트웨어 의료기기에 기존의 시판전 허가(Premarket Approval, PMA) 절차를 그대로 적용하면 위험도가 낮은 소프트웨어 의료기기도 시장에 나오기 어려워 환자들이 혜택을 볼 수 없게 된다는 것이었다. 이러한 문제점을 인지한 미국 식품의약품안전청(FDA)은 2017년 소프트웨어 의료기기에 대한 사전 인증(Pre-Cert) 프로그램을 시범적으로 실시하였다.40) 이 프로그램은 개별 제품에 초점을 맞추기 보다는 품질 기준을 충족하는 기업을 사전인증 하겠다는 접근이다. 소프트웨어의 설계, 유지·보수, 공급사설망, 기업평판 등을 분석하여 사전인증을 받은 기업은 간소화된 절차를 거치도록 함으로써 더 적은 데이터를 제출하고도 제품을 일단 출시할 수 있도록 하되, 그 후에 시장에36)의료기기에 해당하는 소프트웨어는 가) 의료용 빅데이터를 기반으로 의료정보를 분석하", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 23}}
{"id": "doc1_chunk24", "text": "록 함으로써 더 적은 데이터를 제출하고도 제품을 일단 출시할 수 있도록 하되, 그 후에 시장에36)의료기기에 해당하는 소프트웨어는 가) 의료용 빅데이터를 기반으로 의료정보를 분석하여 얻은 임상정보(예: 종양 병변 크기·위치 등)를 이용하여 환자의 질병 유무, 상태 등에 대한 가능성 정도를 자동으로 진단·예측, 모니터링하거나 치료하는 소프트웨어와 나) 의료용 빅데이터를 기반으로 의료영상, 체외진단 기기로부터 나온 시그널, 신호획득시스템(심전계, 뇌파계 등)에서 나오는 패턴 또는 시그널을 분석하여 진단·치료에 필요한 임상정보를 제공하는 소프트웨어로 나뉜다. 한편 의료기기에 해당하지 않는 의료용 소프트웨어로는 의료기관의 행정사무(병실·재고관리, 전자수속 등)를 지원하는 소프트웨어, 운동·레저 및 일상적인 건강관리 목적의 소프트웨어, 교육·연구 목적의 소프트웨어, 질병 치료·진단 등과 관계 없는 의료기록 관리 목적의 소프트웨어, 의료인에게 환자의 건강정보 또는 진료정보를 정리 및 추적하는 툴을 제공하거나 의학정보에 쉽게 접근하도록 도움을 주는 소프트웨어 등이 있다. 건강보험심사평가원, 혁신적 의료기술의 요양급여 여부 평가 가이드라인-AI 기반 병리학 분야, 2020. 37) 의료기기법 제3조, 동법 시행규칙 별표 1.38) 박정연, “의료기기 진입규제의 변화: 공법적 정당화 논거와 규제 방향성”, 「법학논총」, 제46집(2020).39)의료기기법 시행규칙 제4조, 제9조. 이미 인허가를 받은 의료기기와 본질적으로 동등한지 여부는 의료기기의 특성에 따라 다르나 일반적으로는 기존 제품과 사용목적 및 작동원리가 같고 성능", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 24}}
{"id": "doc1_chunk25", "text": "기기법 시행규칙 제4조, 제9조. 이미 인허가를 받은 의료기기와 본질적으로 동등한지 여부는 의료기기의 특성에 따라 다르나 일반적으로는 기존 제품과 사용목적 및 작동원리가 같고 성능, 원재료 또는 사용방법 등이 동등한 의료기기를 본질적으로 동등한 의료기기로 판단한다. 의료기기 허가·신고·심사 등에 관한 규정 별표 5, 별표 7. 40) FDA, Guidance on Software as a Medical Device(SAMD): Clinical Evaluation\n\n비교사법 제29권 4호(통권 제99호)\n226\n서 실제 임상에서의 성능을 보고 제품을 검증한다는 ‘총 제품 수명주기 접근방법(Total product lifecycle approach, TPLC approach)’을 취한 것이다. 식품의약품안전청(FDA)은 2017년 9월 100여개 업체의 신청을 받아 그 중 9개 회사를 선발하여 파일럿 프로그램에 참여시켰다.41)한편 우리나라에서도 2019년 의료기기산업 육성 및 혁신의료기기 지원법을 제정하면서, 미국의 사전 인증(Pre-Cert) 프로그램과 유사한 접근방법을 채택하였다고 알려져 있다. ‘기존의 의료기기에 비하여 기술집약도가 높고 혁신 속도가 빠른 분야의 첨단 기술의 적용이나 사용방법의 개선 등을 통하여 기존의 의료기기나 치료법에 비하여 안전성, 유효성을 현저히 개선하였거나 개선할 것으로 예상되는 의료기기’를 혁신의료기기42)로 지정하여 단계별 심사43) 및 우선 심사를 허용함으로써 신속히 시판될 수 있도록 하는 것, 그리고 혁신의료기기소프트웨어 제조기업 인증제를 도입하여 허가시 일부 자료 제출을 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 25}}
{"id": "doc1_chunk26", "text": "2)로 지정하여 단계별 심사43) 및 우선 심사를 허용함으로써 신속히 시판될 수 있도록 하는 것, 그리고 혁신의료기기소프트웨어 제조기업 인증제를 도입하여 허가시 일부 자료 제출을 면제하는 것이 그 주된 내용이다.44)(3) 기계학습 의료기기(Machine Learning-enabled Medical Devices, MLMD)를 어떻게 규제할 것인가?인공지능 의료기기의 규제와 관련하여 남아있는 중요한 문제 중 하나는, 계속하여 적응하고 변화하는 알고리즘을 어떻게 규제할 것인가 하는 것이다. 최근까지 허가나 인증을 받은 인공지능 의료기기는 모두 잠긴 알고리즘(Locked algorithm), 즉 시판 후에 새로운 환경에 맞추어 변화하지 않는 제품들이었다.45) 현재로서는 알고리즘이 사용환경에서 변화한다면 이러한 의료기기는 규제당국의 심사를 다시 받아야 할 것이고, 제조업자로서는 갱신(update)을 위한 심사에서 허가가 거절되거나 지연될 위험을 피하기 위해서라도 알고리즘을 갱신하지 않는 편을 택할 우려가 있다.46) 그러나 이러한 잠긴 알고리즘만 시판을 허용하게 되면 실시간으로 적응하고 기기 성능을 최적화하여 계속적으로 의료의 질을 향상시킬 수 있는 적응하는(adaptive) 인공지능 기술을 활용할 수 있는 가능성은 아예 배제되는 결과가 될 것이다. 이에 미국 식품의약품안전청(FDA)은 지속적으로 성능을 향상시키는, 즉 실시간 학습하고, 적41)Apple, Fitbit, Johnson & Johnson, Pear Therapeutics, Phosphorus, Roche, Samsung, Tidepool, 및 Ve", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 26}}
{"id": "doc1_chunk27", "text": " 적41)Apple, Fitbit, Johnson & Johnson, Pear Therapeutics, Phosphorus, Roche, Samsung, Tidepool, 및 Verily가 파일럿 프로그램에 참여하였다.42) 의료기기산업 육성 및 혁신의료기기 지원법 제2조 제4호. 43)단계별 심사제도는 업체의 개발단계를 4단계로 나누어 각 단계별로 심사를 실시하는데, 심사자는 단계별로 자료 제출일로부터 30일 내에 검토 결과를 통보하는 것을 원칙으로 하고, 단계별 심사가 완료되면 적합통지서를 발급하며, 개발 완료 후 품목허가를 신청하면 신청 즉시 허가가 이루어진다. 식품의약품안전처, 첨단의료기기 단계별 허가심사 가이드라인, 2016, 6면.44)의료기기산업 육성 및 혁신의료기기 지원법에서는 혁신의료기기 및 혁신소프트웨어에 대한 허가심사특례제도를 마련하여 단계별 심사제도 및 우선심사제도를 적용하도록 하고 있다. 박정연, 위의 글, 187-188면.45) Minssen, 5.46)Sara Gerke, Boris Babic, Theodoros Evgeniou & I. Glenn Cohen, The need for a system view to regulate artificial intelligence/machine learning-based software as a medical device, 53 NPJ Digital Medicine 1 (2020).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 227\n응하며, 성능을 최적화시키는 인공지능 의료기기를 허용하기 위", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 27}}
{"id": "doc1_chunk28", "text": "1 (2020).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 227\n응하며, 성능을 최적화시키는 인공지능 의료기기를 허용하기 위하여 앞서 살펴 본 총 제품 수명주기 접근방법(Total product lifecycle approach)이라는 큰 틀 안에서, 시판 전에 미리 시판 후에 예상되는 수정사항과 재훈련(retraining) 및 갱신(update) 방법론을 포함하는 “Predetermined Change Control Plan”을 제출하여 심사받도록 하고, 시판 후에도 지속적으로 모니터링하는 방안을 논의 중이다.47) 한편 우리나라에서는 아직 기계학습 의료기기의 특성이 반영된 규제법규는 마련되지 않은 것으로 보인다.48)4. 남아 있는 문제들지금까지 인공지능 의료기기의 허가 또는 인증 건수를 살펴보면, 미국은 2020년 한 해에만 약 100건,49) 우리나라는 같은 해에 약 50건50)으로, 시장 규모를 감안할 때 우리나라가 인공지능 의료기기 시장에 상당히 적극적으로 참여하고 있는 것을 알 수 있다. 그러나 인공지능 의료기기가 허가 또는 인증을 받은 후에 우리나라 환자들이 실제로 그 혜택을 보기 위해서는 또 다른 절차, 즉 신의료기술평가를 거쳐 국민건강보험법에 따른 요양급여 또는 비급여 항목으로 등재하는 절차를 거쳐야 한다.51) 특히 보험 수가 인정의 문제는 인공지능 의료기기가 실제 임상에 도입되는 데에 또 하나의 장애물로 인식되고 있다. 보험 수가를 인정받지 못하면 의료기관 또는 의사로서는 비싼 비용을 들여 인공지능 의료기기를 도입할 유인이 줄어들기 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 28}}
{"id": "doc1_chunk29", "text": " 실제 임상에 도입되는 데에 또 하나의 장애물로 인식되고 있다. 보험 수가를 인정받지 못하면 의료기관 또는 의사로서는 비싼 비용을 들여 인공지능 의료기기를 도입할 유인이 줄어들기 때문이다. 보건복지부와 건강보험심사평가원은 가장 개발이 활발한 AI 영상 및 병리, 3D 프린팅 분야에 대해 건강보험 적용에 대한 예측가능성을 높이고 평가기간을 단축하고자 건강보험 등재 및 보상에 대한 가이드라인을 마련하였다.52) 주요 골자는 환자의 치료에 도움이 되거나 비용절감이 입47)FDA, Proposed Regulatory framework for public comment for Modifications to AI/ML-Based Software as a Medical Device (SaMD); FDA, AI/ML-Based Software as a Medical Device Action Plan. FDA의 위 discussion paper와 잠긴(“locked”) 또는 변화하는(“adaptive”) 알고리즘의 취급에 대한 논의로는, Boris Babic, Sara Gerke, Theodoros Evgeniou & I. Glenn Cohen, Algorithms on regulatory lockdown in medicine, 366 Science 1202 (2019). 48)박정연, 위의 글, 200면; 손승호 외 4인, “빅데이터 및 인공지능 기술 적용 의료기기의 허가심사 방안”, 「대한전자공학회 학술대회 논문집」(2018), 1732면.49)U.S. Food and Drug Administration, Artifici", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 29}}
{"id": "doc1_chunk30", "text": "기술 적용 의료기기의 허가심사 방안”, 「대한전자공학회 학술대회 논문집」(2018), 1732면.49)U.S. Food and Drug Administration, Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices, https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices50)2021년 5월 현재 국내 시장에 출시된 인공지능 의료기기는 총 112개이다. 식품의약품안전처, 2022. 5. 12.자 보도자료, 7면. 51)박정연, 위의 글, 183면. 신의료기술평가란 해당기기를 사용한 새로운 의료기술이 안전성과 유효성을 갖추었는지를 의료법 제53조에 의거하여 체계적 문헌고찰방법론을 토대로 신의료기술평가위원회 및 분야별 전문평가(소)위원회에서 심의하는 절차이다. 위의 글.52)보건복지부/건강보험심사평가원, 혁신적의료기술의 요양급여여부 평가 가이드라인-AI기반 의료기술(영상의학분야) & 3D 프린팅 이용 의료기술, 2019; 보건복지부/건강보험심사평가원, 혁신적의료기술의 요양급여여부 \n\n비교사법 제29권 4호(통권 제99호)\n228\n증된 경우에 별도 수가를 인정하자는 것이다. 위 가이드라인에서는 AI 의료기술을 그 효과에 따라 4단계로 구분하여, 진료 업무 효율 향상이 있거나 기존 행위와 유사한 수준의 진단능력만을 가진 경우에는 별도 보상하지", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 30}}
{"id": "doc1_chunk31", "text": " 것이다. 위 가이드라인에서는 AI 의료기술을 그 효과에 따라 4단계로 구분하여, 진료 업무 효율 향상이 있거나 기존 행위와 유사한 수준의 진단능력만을 가진 경우에는 별도 보상하지 않고, 기존 행위 대비 현저하게 진단능력이 향상되거나, 새로운 진단적 가치를 창출하거나, 또는 치료 효과성이 있는 경우, 또 이에 더해 비용 효과성을 입증한 경우라면 AI 의료기술의 경우 건강보험 적용을 고려해볼 만 하다고 밝히고 있다.53) 문제는 현재 우리나라에 나와 있는 인공지능 의료기기들이 이 요건을 만족시키기는 쉽지 않다는 것인데, 아직까지 우리나라에서 별도로 수가를 인정받은 인공지능 의료기기는 없는 것으로 알려져 있다.Ⅲ. 인공지능 의료기기 오작동으로 인한 책임 분배1. 문제의 특수성이렇게 인공지능 기술을 활용한 의료기기가 여러 가지 장애물을 극복하고 임상 현장에서 활용된다 하더라도 항상 좋은 결과만 얻을 수 있는 것은 아닐 것이다. 인공지능 의료기기가 편향성(bias)을 띠어 여성이나 노인 또는 소수인종에 관하여 저하된 성능을 보일 수 있다.54) 혹은 소프트웨어 오류가 발생하거나 보안에 문제가 발생하여 인공지능 의료기기가 오작동할 수도 있다.55) 이런 특별한 이유가 없더라도, 확률적 예측을 하는 인공지능의 특성상 잘못된 결정을 내리는 경우는 언제든지 발생할 수 있다고 볼 수도 있다. 이처럼 인공지능 의료기기의 잘못된 권고로 환자의 건강이 침해되는 악결과가 발생하면 과연 누가 책임을 져야 할까?인공지능 자체에 법인격을 인정하고 있지 않은 현행 법제상 인공지능 의료기기를 사용한 의료인이 일차적인 책임의 주체로 고려될 수", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 31}}
{"id": "doc1_chunk32", "text": "해되는 악결과가 발생하면 과연 누가 책임을 져야 할까?인공지능 자체에 법인격을 인정하고 있지 않은 현행 법제상 인공지능 의료기기를 사용한 의료인이 일차적인 책임의 주체로 고려될 수밖에 없다.56) 지금까지 인공지능 의료기기의 오작동으평가 가이드라인-AI기반 의료기술(병리학분야), 2020. 53) 위의 글.54)인공지능 의료기기는 통상 각종 자원이 풍부한 대학병원에서 수집한 데이터를 활용하여 훈련되는 경우가 많은데, 같은 대학병원에서 해당 의료기기를 활용한다면 문제가 없겠지만, 대학병원처럼 인적, 물적 자원이 풍부하지 않은 예컨대 지방의 작은 병원에서 인공지능 의료기기를 활용하는 경우 그 병원을 이용하는 환자들의 인구구성이 대학병원의 환자들의 구성과 다른 경우 성능이 저하되는 경우가 있을 수 있다. 또한 자원이 풍부한 대학병원과는 달리 자원이 부족한 의료환경에서는 추천된 치료방법을 적용하기 어려운 경우도 있을 수 있고 치료의 질이 떨어져 도움이 되지 않거나 오히려 해가 되는 경우도 있을 수 있다. W. Nicholson Price II, 각주 23, 위의 글, 74~79면.55)물론, 의료과실로 문제될 수 있는 의사의 책임은 민사상 책임 외에도 형사상 책임과 행정상 책임이 있다. 주호노, 의사법학론, 법문사, 2017, 727~230쪽. 다만, 이 글에서는 민사상 책임을 중심으로 논의를 한정한다.56)인공지능에게 법인격을 인정하자는 주장은 1992년 Lawrence Solum에 의하여 제기된 바 있고 (Lawrence B. Solum, Legal Personhood for Artificial Intellige", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 32}}
{"id": "doc1_chunk33", "text": "주장은 1992년 Lawrence Solum에 의하여 제기된 바 있고 (Lawrence B. Solum, Legal Personhood for Artificial Intelligence, 70 N.C. L. Rev. 1231, 1252-53 (1992)), 2017년 자동화 로봇에게 법인으로서의 지위를 부여하여 손해를 배상하도록 하자는 주장이 담긴 유럽 의회의 보고서(Comm. \n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 229\n로 인한 책임에 관한 논의는 주로 의사의 의료과오책임을 위주로 이루어져 왔으나, 의사뿐만 아니라 의료기관, 인공지능 의료기기 제조업자, 보험, 기타 배상제도를 포함하는 더 큰 틀에서 이 문제를 바라볼 필요가 있다. 책임 분배의 문제는 환자가 누구로부터 배상을 받을 수 있는가의 문제에 그치는 것이 아니라, 인공지능 의료기기가 개발되고 임상에 도입될 수 있을 것인지 여부에도 직·간접적으로 영향을 미친다.57) 따라서 기술 혁신을 저해하지 않으면서 인공지능 의료기기의 안전한 이용을 도모하는 균형잡힌 접근방법이 필요하다.2. 의사의 책임(1) 의료과오책임의료인이 진단 및 치료상의 주의의무를 위반하여 환자의 생명, 신체, 건강을 침해한 경우에 지게 되는 책임을 의료과오책임이라고 한다.58) 의료과오책임은 의료계약의 불완전이행으로 인한 채무불이행책임 또는 불법행위책임으로 구성할 수 있으나, 어느 쪽으로 구성하든 의사가 환자에 대한 치료에 있어서 최선의 주의의무를 다하지 않았다는 점을 환자 측에서 증명하여야 한다는 점에서는 차이가 없다.59) 판", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 33}}
{"id": "doc1_chunk34", "text": "로 구성할 수 있으나, 어느 쪽으로 구성하든 의사가 환자에 대한 치료에 있어서 최선의 주의의무를 다하지 않았다는 점을 환자 측에서 증명하여야 한다는 점에서는 차이가 없다.59) 판례에 따르면 책임의 전제가 되는 주의의무란, 진찰, 치료 등의 의료행위와 관련하여 환자의 구체적 증상이나 상황에 따라 위험을 방지하기 위하여 요구되는 최선의 조치를 행하여야 할 의무이고, 이는 의료행위를 할 당시 의료기관 등 임상의학 분야에서 실천되on Legal Affairs, Eur. Union Parliament, Rep. with Recommendations to the Comm’n on Civ. L. Rules on Robotics, at 18 (2017))에 의하여 논란이 재점화되었다. 그러나 이에 대하여는 위험을 야기한 자연인이나 법인에게 손해를 귀속시키면 충분하다는 강한 반대의견이 있었다 (Eur. Comm’n, Expert Group on Liability and New Technologies, Liability for Artificial Intelligence and Other Emerging Digital Technologies 38 (2019)). 최근까지 이어지고 있는 인공지능에 대한 법인격 부여에 관한 논란에 대하여는, Benny Chan, Applying a Common Enterprise Theory of Liability to Clinical AI Systems, 47 Am. J. L. & Med. 351, 369 (2021) 참조. 의료영역에서 인공지능을 이용한 진단행위나 검사결과의 판독행위와 같이 인", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 34}}
{"id": "doc1_chunk35", "text": "Clinical AI Systems, 47 Am. J. L. & Med. 351, 369 (2021) 참조. 의료영역에서 인공지능을 이용한 진단행위나 검사결과의 판독행위와 같이 인공지능의 판단에 독립성이 있다고 볼 수 있는 경우 인공지능에 법인격을 부여할 가능성이 있다고 보고, 이를 전제로 채무불이행책임과 불법행위책임을 분석한 글은, 백경희/장연화, 각주 13, 위의 글, 111~114면 참조. 57)George Maliha, Sara Gerke, I. Glenn Cohen & Ravi B. Parikh, Artificial Intelligence and Liability in Medicine: Balancing Safety and Innovation, 99 The Milbank Quarterly 629, 629-30 (2021).58)실무에서는 주로 불법행위책임으로 구성되는데, 이는 환자 가족들이 위자료청구권을 실현하기 위한 것으로 이해된다. 이상돈/김나경, 의료법강의(제4판), 법문사, 2020, 129-130면. 그 외에도 배상의무자가 누구인지, 지연손해금의 기산일, 소멸시효기간 등에 있어서도 차이가 있다.59)백경희/장연화, “의료판례의 동향과 문제: 민사법적 쟁점과 전망을 중심으로”, 「한국의료법학회지」, 제26권 제1호(2018), 226-227면 (계약책임으로 구성하더라도 의사의 치료채무의 성질을 수단채무로 파악하는 우리 판례에 따르면 환자 측에서 의사가 최선의 주의의무를 다하지 않았다는 불완전이행을 증명할 수밖에 없음). 청구원인을 채무불이행으로 구성하더라도 진료의무의 성격은 일반적으로 수단채무", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 35}}
{"id": "doc1_chunk36", "text": " 판례에 따르면 환자 측에서 의사가 최선의 주의의무를 다하지 않았다는 불완전이행을 증명할 수밖에 없음). 청구원인을 채무불이행으로 구성하더라도 진료의무의 성격은 일반적으로 수단채무여서 나쁜 결과가 발생하였다는 사정만으로 곧바로 진료채무의 불완전이행이 있다고 볼 수 없다는 취지의 판례는, 대법원 1988. 12. 13. , 85다카1491 판결 등 참조.\n\n비교사법 제29권 4호(통권 제99호)\n230\n고 있는 의료행위의 수준을 기준으로 하며, 이처럼 요구되는 의료 수준은, 통상의 의사에게 의료행위 당시 일반적으로 알려져 있고 또 시인되고 있는 이른바 의학상식을 뜻하므로 진료 환경 및 조건, 의료행위의 특수성 등을 고려하여 규범적인 수준으로 파악되어야한다고 한다.60) 판례가 요구하는 의료수준을 판단함에 있어 일부의 대학, 병원, 연구소 등에서만 알려져 있고 대부분의 의사에게 그 당시 널리 알려져 있지 않은 의학적 전문지식은 배제된다고 이해된다.61)이러한 판단 기준은 미국에서도 크게 다르지 않다. 미국에서 의료과오책임은 의사가 의료 수준(standard of care)에서 벗어남으로 인하여 손해가 발생했을 것을 요건으로 하고,62) 이때 의료 수준(standard of care)은 동일 또는 유사한 상황에서 같은 분야의 평균적인 능력있는 의사가 따르는 일반적으로 승인되고 받아들여지는 관습과 절차를 따랐는지에 따라 결정된다.63) 과거에는 지방의 소형 병의원의 의사들에게는 도시의 종합병원 의사들에게 요구되는 기준보다 낮은 기준을 요구해야 한다는 소위 locality rule이 존재하였으나 최근에는 일반의를 제외", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 36}}
{"id": "doc1_chunk37", "text": "에는 지방의 소형 병의원의 의사들에게는 도시의 종합병원 의사들에게 요구되는 기준보다 낮은 기준을 요구해야 한다는 소위 locality rule이 존재하였으나 최근에는 일반의를 제외하고는 미국 전역의 전문의를 기준으로 판단하는 경향이다.64)따라서 인공지능 의료기기의 치료 권고를 그대로 믿고 의료행위를 한 의사도 요구된 주의의무의 기준, 즉 의료수준에 미치지 못한 것으로 판단되면 책임을 질 수 있다.65) 의사가 인공지능 의료기기의 권고와는 별개로, 요구되는 의료수준을 독립적으로 적용할 의무가 있다고 보는 것이다.66) Price 교수는 인공지능 의료기기의 권고를 따르거나 따르지 않음으로 인하여 환자에게 나쁜 결과가 발생한 경우의 의사의 책임 여부와 관련하여 여러 가지 경우의 수를 분석한 표를 제시하였는데,67) 아래의 표는 이를 간략하게 변형한 것이다.환자에게 나쁜 결과가 발생한 경우를 전제로 하여 AI 권고의 의료수준 부합 여부(×2), 의사가 인공지능 의료기기의 권고를 따르는지 여부(×2)에 따라 경우의 수를 산정하면 총 네 가지 경우가 나온다. 인공지능 의료기기의 권고가 맞는데 의사가 이에 따르지 않았거나 틀린 권고를 따른 경우에만 환자에게 나쁜 결과가 발생할 것이므로 AI 권고의 정확성 여부는 의사가 인공지능 의60)대법원 1999. 3. 26., 98다45379, 45386 판결. 이러한 의료과실의 개념은 계약책임이든 불법행위책임이든 동일하다. 이상돈/김나경, 위의 책, 130면.61) 석희태, “의료과실 판단기준에 관한 학설·판례의 동향”, 「의료법학」, 창간호(2000), 336쪽.62) Mahl", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 37}}
{"id": "doc1_chunk38", "text": "위책임이든 동일하다. 이상돈/김나경, 위의 책, 130면.61) 석희태, “의료과실 판단기준에 관한 학설·판례의 동향”, 「의료법학」, 창간호(2000), 336쪽.62) Mahlia et al., 위의 글.63)A. Michael Froomkin, Ian Kerr & Joelle Pineau, When AIs Outperform Doctors: Confronting the Challenges of a Tort-Induced Over-Reliance on Machine Learning, 61 Ariz. L. Rev. 33, 52-54 (2019).64) 위의 글.65)Mahlia et al., 위의 글; Maxwell J. Mehlman, Medical practice guidelines as malpractice safe harbors: illusion or deceit?, 40 JOURNAL OF LAW, MEDICINE & ETHICS 286, (2012).미국의 경우, 인공지능 의료기기의 사용과 관련한 판례가 아직 축적되지는 않았지만, 유사한 사례에서 법원이 취한 태도에 비추어 볼 때, 인공지능 의료기기의 오류로 인한 책임을 의사가 지게 될 것으로 예상된다. Ibid.66) Mahlia et al., 위의 글; Tesauro v Perrige, 650 A2d, 1079 (Pa Super Ct 1994).67)W. Nicholson Price II, Potential LIability for Physicians Using Artificial Intelligence, 322 JAMA 1765, 1765-6", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 38}}
{"id": "doc1_chunk39", "text": "on Price II, Potential LIability for Physicians Using Artificial Intelligence, 322 JAMA 1765, 1765-66 (2019).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 231\n[표 1: 환자에게 나쁜 결과가 발생한 경우 의사의 책임]AI의 권고의사의 선택AI의 권고가 정확했는지 여부 책임 여부1의료수준에 부합따름부정확 책임 없음2 따르지 않음정확책임 있음3의료수준을 일탈따름부정확책임 있음4 따르지 않음정확책임 없음료기기의 권고를 따르는지 여부에 연동되어 결정된다. 이때 의사가 책임을 지는지 여부를 따져보면, 인공지능 의료기기의 권고가 의료수준에 부합하는데 따르지 않은 경우와 부합하지 않는데 따른 경우(2, 3)에는 책임이 있으나, 그 반대의 경우(1, 4)에는 책임이 없다. Price 교수는, 인공지능 의료기기의 도움을 받아 임상적 의사결정을 내리는 경우에도 현재 요구되는 의료수준에 따르는 한 책임을 지지 않기 때문에, 의사로서는 인공지능 의료기기를 단지 확인하는 용도(confirmatory tool)로만 쓰는 것이 가장 안전한 셈이 된다고 한다.68) 결국, 현재의 책임 법리를 그대로 적용하면 의사는 책임질 가능성을 피하기 위하여 인공지능 의료기기의 권고가 아니라 당시 의료수준에 맞추어 최종 결론을 내리게 될 것이므로 인공지능 의료기기의 잠재적 가치를 최소화하게 되는 것이다.69) 현재의 인공지능 의료기기의 발전 단계는 아직 그 성능이 인간을 뛰어넘거나 인간을 대체하는 것이 아니라, 인", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 39}}
{"id": "doc1_chunk40", "text": "것이므로 인공지능 의료기기의 잠재적 가치를 최소화하게 되는 것이다.69) 현재의 인공지능 의료기기의 발전 단계는 아직 그 성능이 인간을 뛰어넘거나 인간을 대체하는 것이 아니라, 인간의 의사결정의 시간을 단축시키거나 실수를 줄여주는 보조적 기능에 머무르고 있다는 점을 고려하면, 이러한 한계는 당장은 큰 문제라고 느껴지지는 않을 수 있다.70) 또한 과실 판단의 기준이 인공지능의 활용을 고려하여 변화할 가능성도 완전히 배제할 수는 없다. 이처럼 의료수준을 벗어나는 인공지능의 추천을 따르는 경우 책임을 질 위험이 늘어나게 되므로 68) 위의 글, 1765.69)위의 글. 의료 수준(standards of care)의 변화가 의사의 행동의 변화에 큰 영향을 미친다는 연구결과는, Michael Frakes, The Impact of Medical Liability Standards on Regional Variations in Physician Behavior: Evidence from the Adoption of National-Standard Rules, 103 American Economic Review 257 (2013).70)자율주행자동차의 자동화 수준 5단계별로 책임 분석을 달리하는 논의를 차용하여, 인공지능 영상의료판독에서도 발전 단계별로 책임 분배 여부를 판단하자는 논의도 있다(정창록 외 3인, “4차 산업혁명 시대의 기술 책임론에 대한 고찰: 자율주행자동차 기술 발전 5단계와 인공지능 영상의료판독 기술 발전 5단계를 중심으로”, 「한국의료법학회지」, 제25권 제1호(2017), 155~172면). 그러", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 40}}
{"id": "doc1_chunk41", "text": "론에 대한 고찰: 자율주행자동차 기술 발전 5단계와 인공지능 영상의료판독 기술 발전 5단계를 중심으로”, 「한국의료법학회지」, 제25권 제1호(2017), 155~172면). 그러나 의사와 같이 면허를 받아 업무를 독점하는 인간전문직이 인공지능의 보조를 받아 의사결정을 하는 경우는 자율주행자동차의 소비자 지위에 놓인 운전자의 경우와는 차이가 있고, 의료계약에 따라 의사와 법적 관계를 맺는 환자의 경우는 자동차 사고 이전에는 아무런 특별 관계가 없는 제3자인 자동차 사고 피해자의 경우와 차이가 있다는 지적도 있다(설민수, 위의 글, 268-269면). 물론 자율주행자동차의 경우 책임 논의와 인공지능 의료기기의 경우 책임 논의는 위와 같은 이유로 구별되어야 마땅할 것이나, 인공지능 의료기기 기술의 발전 단계에 따라 의료행위에 관한 의사결정에서의 인공지능 의료기기의 역할 또는 의사의 역할이 달라지고 그 변화가 결국 책임관계에 영향을 미칠 수 있다는 점에서 기술 발전 단계별로 분석하는 접근방법은 여전히 의미가 있다.\n\n비교사법 제29권 4호(통권 제99호)\n232\n인공지능 의료기기의 잠재적 효용을 감소시키는 결과에 이를 것이라는 Price 교수의 주장을 검증하기 위하여 일반인 2,000명을 대상으로 실시된 최근 한 연구에 따르면, 의사가 의료수준을 벗어나는 인공지능의 추천(nonstandard recommendation)을 받았고, 그 인공지능의 추천이 실제로 그릇된(incorrect) 경우라도 잠재적 배심원은 의사가 이를 따른 것이 합리적이었다고 판단할 가능성이 높다고 한다.71) 비록 이 연구는 배심제를 전제로 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 41}}
{"id": "doc1_chunk42", "text": "지능의 추천이 실제로 그릇된(incorrect) 경우라도 잠재적 배심원은 의사가 이를 따른 것이 합리적이었다고 판단할 가능성이 높다고 한다.71) 비록 이 연구는 배심제를 전제로 미국에서 이루어진 연구이지만, 일반인들이 의사가 인공지능의 추천이 의료수준을 벗어나는 경우에도 이를 따른 것을 합리적이라고 본 것은, 적어도 일반인의 인식 속에서는 과실 판단의 기준이 인공지능을 고려하여 변화하고 있다고도 볼 수 있을 것이다.72) 향후 의사보다 뛰어난 성능을 가진 인공지능 의료기기가 널리 쓰이게 되면, 주의의무의 기준이 되는 의료수준(standard of care)도 결국 그에 맞추어 상향될 것이다.73) 인공지능 의료기기가 의사보다 더 뛰어난 실력을 갖추었을 뿐만 아니라 업무흐름에 방해가 되지 않고, 병원 측의 비용부담도 합리적인 선이라면, 의료수준을 인공지능 의료기기의 성능에 맞추어 상향하지 않을 이유가 없을 것이다. 이때는 의사들이 오히려 인공지능 의료기기가 내놓는 진단이나 치료방법을 따라야 할 주의의무를 지게 될 수도 있다.74) 인공지능 의료기기가 인간의 의사결정보다 일관되게 뛰어난 성능을 보인다면, 이에 따르는 것이 평균적으로 환자의 건강에 대한 침해를 줄이는 길이 될 것이기 때문이다. 그러나 인간 의사보다 뛰어난 성능을 가진 인공지능 의료기기가 널리 쓰이게 된다 하더라도, 의사가 인공지능 의료기기에 전적으로 의존하기 보다는 그 결정을 검증하고 필요시 무시(override)하게 함으로써, 인간과 기계가 한 팀을 이루어 서로를 보완하도록 하여야 한다.75) 아무리 인간 의사보다 뛰어난 성능을 갖춘 인공지능 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 42}}
{"id": "doc1_chunk43", "text": "결정을 검증하고 필요시 무시(override)하게 함으로써, 인간과 기계가 한 팀을 이루어 서로를 보완하도록 하여야 한다.75) 아무리 인간 의사보다 뛰어난 성능을 갖춘 인공지능 의료기기가 개발된다고 하더라도, 완벽한 성능을 갖추지 않은 이상 간혹 위양성(false positive) 또는 위음성(false negative)의 권고를 제시하게 마련일 것이고, 이러한 오류 중 일부는 인간 의사라면 하지 않았을 실수일 가능성이 있기 때문71)Kevin Tobia, Aileen Nielsen & Alexander Stremitzer, When Does Physician Use of AI Increase Liaiblity?, 62 J. Nuclear Med. 17 (2021) (의료수준을 벗어나는 추천을 받은 경우, 응답자들은 의사가 이를 따르는 것(accept)에 따르지 않는 것(reject)에 비해 약간이나마 더 높은 합리성 점수(reasonablness rating)를 부여하였고, 이 차이는 통계적으로 유의하였음). 미국에서의 일반인의 인식에 대한 조사는 잠재적 배심원의 인식을 조사한다는 측면에서 의미가 있고, 배심원의 판단에 이르지 않고 분쟁이 화해로 종결되는 경우에도 배심원의 판단이 어떠할 것이라는 예측에 근거하여(in the shadow of law) 화해가 이루어질 가능성이 높다.72)W. Nicholson Price II, Sara Gerke & I. Glenn Cohen, How Much Can Potential Jurors Tell Us About Liability for Medical Artific", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 43}}
{"id": "doc1_chunk44", "text": "ra Gerke & I. Glenn Cohen, How Much Can Potential Jurors Tell Us About Liability for Medical Artificial Intelligence?, 62 J. Nuclear Med. 15, 15 (2021).73) Froomkin et al., 위의 글.74)이러한 경우에는 과실을 피하기 위하여 의사가 ‘최신의’ 인공지능 의료기기를 도입하여야 할 의무가 있다고 보아야 한다는 주장은, Philipp Hacker, Ralf Krestel, Stefan Grundmann & Felix Naumann, Explainable AI under contract and tort law: legal incentives and technological challenges, 28 Artificial Intelligence and Law 415, 421-423 (2020).75)다만 이러한 시점이 오면 전문의에 대한 수요가 줄고 수련 기회도 줄어들게 되어 인공지능 의료기기가 오작동하는 경우에 이를 감시하고 검증할 의사 인력도 부족해질 것이라는 예측으로는, Froomkin et al., 위의 글.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 233\n이다. 따라서 의사가 언제나 인공지능의 결정을 그대로 따르는 것이 책임을 회피하는 방책이 되지 않도록, 의사에게 인공지능의 결정이 잘못되었다는 의학적 근거가 있다면 이를 따르지 않을 주의의무를 부과하는 등 진단이나 치료방법을 결정함에 있어 의사의 실질적 참여를 의무화하여야 한", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 44}}
{"id": "doc1_chunk45", "text": "도록, 의사에게 인공지능의 결정이 잘못되었다는 의학적 근거가 있다면 이를 따르지 않을 주의의무를 부과하는 등 진단이나 치료방법을 결정함에 있어 의사의 실질적 참여를 의무화하여야 한다.76) 인공지능 의료기기의 결정에 대한 검증을 위한 구체적 기준 마련은 국회나 법원을 통해서도 이루어질 수 있을 것이나, 과실 판단의 기준이 되는 의료수준이 통상의 의사를 기준으로 한다는 점을 고려하면, 의사들이 주도하여 이러한 기준을 마련하는 것도 한 방법이 될 수 있을 것이다.77)(2) 의사의 설명의무 위반책임의사는 의료과오책임을 지지 않는 경우라도 설명의무 위반으로 인한 책임을 질 여지가 있다. 의사 측과 환자 측 사이에는 통상 의료정보의 보유량과 전문지식의 현격한 차이가 존재하므로, 환자의 자기결정권을 충분히 보장하기 위해 의사는 설명의무를 진다.78) 즉, 의사는 “환자가 스스로 자기결정권을 적절히 행사하여 의료행위의 시행 여부와 방법을 판단하여 선택할 수 있도록, 의료행위를 시행하기 전에 진료시술의 방법, 질병의 유무와 종류에 대한 진단 결과, 질병의 예후와 경과, 치료방법과 수단, 합병증과 부작용 등의 위험을 고지하여야 할 의무”가 있다.79) 인공지76)의사가 인공지능 의료기기와 다른 의견을 내는 경우 이에 대한 의학적 근거, 해당 의료기관의 특수한 상황 등에 대하여 주장, 입증이 가능하도록 증거를 남겨야 하고, 최종 결론에 대하여 협진 등 공동의사결정과정을 거치는 등 다시 한번 검증하는 것이 바람직하다는 견해는, 배현아, 위의 글. 의사는 인공지능 의료기기의 권고뿐만 아니라 의학적 경험을 고려하여 종합적인 판단을", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 45}}
{"id": "doc1_chunk46", "text": "등 공동의사결정과정을 거치는 등 다시 한번 검증하는 것이 바람직하다는 견해는, 배현아, 위의 글. 의사는 인공지능 의료기기의 권고뿐만 아니라 의학적 경험을 고려하여 종합적인 판단을 내려야 한다는 견해로는, Froomkin et al., 위의 글. 77)W. Nicholson Price II, Medical Malpractice and Blackbox Medicine, in Big Data, Health Law, and Bioethics (I. Glenn Cohen et al., eds.), Cambridge (2017) (구체적으로 위험도가 낮은 치료방법의 경우에는 별도의 검증이 필요하지 않지만, 위험도가 높은 치료방법의 경우에는 검증 절차를 거치도록 하는 것이 바람직함). 의사 협회가 주의의무의 기준으로서의 의료수준에 영향을 미칠 수 있다는 점에 관하여는, Michelle M. Mello, Of Swords and Shields: The Role of Clinical Practice Guidelines in Medical Malpractice Litigation, 149U. Penn. L. Rev. 645 (2001) 참조. 인공지능 의료기기에 대한 평가 및 검증 방법에 대한 논의는, Khalifa et al., Developing a framework for evidence-based grading and assessment of predictive tools for clinical decision support, 19 BMC Med Inform Decis Mak. 1 (2019); Wolff, Rober", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 46}}
{"id": "doc1_chunk47", "text": " predictive tools for clinical decision support, 19 BMC Med Inform Decis Mak. 1 (2019); Wolff, Robert F., Karel GM Moons, Richard D. Riley, Penny F. Whiting, Marie Westwood, Gary S. Collins, Johannes B. Reitsma, Jos Kleijnen, and Sue Mallett. “PROBAST: a tool to assess the risk of bias and applicability of prediction model studies.” Annals of internal medicine 170, no. 1 (2019): 51-58 참조.78)김재완, “로봇수술로 인한 의료과오 민사책임에 있어 과실 판단의 문제”, 「아주법학」, 제14권 제1호(2020), 47면. 이러한 자기결정을 위한 설명 외에도, 의료 개입이 이루어지는 중의 설명 및 요양방법지도와 같은 의료개입 후의 설명도 설명의무의 범주에 포함된다. 이상돈/김나경, 위의 책, 139-140면. 그러나 이 글에서는 인공지능 의료기기의 활용과 관련하여 의료적 개입 전의 자기결정을 위한 설명을 중심으로 논의한다. 한편, 판례는 설명의무의 근거에 관하여, 환자는 헌법 제10조에서 규정한 개인의 인격권과 행복추구권에 의하여 생명과 신체의 기능을 어떻게 유지할 것인지에 대하여 스스로 결정하고 의료행위를 선택할 권리를 갖고(대법원 2017. 2. 15., 2014다230535 판결), 진료계약상의 의무 내지 침", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 47}}
{"id": "doc1_chunk48", "text": "신체의 기능을 어떻게 유지할 것인지에 대하여 스스로 결정하고 의료행위를 선택할 권리를 갖고(대법원 2017. 2. 15., 2014다230535 판결), 진료계약상의 의무 내지 침습 등에 의한 승낙을 얻기 위한 전제로서 의사의 설명의무가 필요하다고(대법원 1994. 4. 15., 93다60935 판결) 설시한다. \n\n비교사법 제29권 4호(통권 제99호)\n234\n능 의료기기의 사용과 관련한 설명의무 또는 인폼드 컨센트(Informed Consent)80)의 문제는 비교적 최근에서야 주목받기 시작한 이슈이다.81) 임상에서 인공지능 의료기기를 도입하여 활용할 때, 어떠한 경우에 설명의무가 있다고 보아야 하는지, 어떠한 정보를 제공해야 하는지, 즉 알고리즘의 설계(architecture)나 인풋 데이터, 편향(bias)의 가능성이나 데이터의 취약점까지 알려주어야 하는지 등에 관하여 해결되지 않은 문제들이 산재해 있다. (가) 우리나라에서의 의사의 설명의무우리 판례는 일반적으로 “의사는 환자에게 수술 등 침습을 가하는 과정 및 그 후에 나쁜 결과 발생의 개연성이 있는 의료행위를 하는 경우 또는 사망 등의 중대한 결과 발생이 예측되는 의료행위를 하는 경우에 있어서 응급환자의 경우나 그밖에 특단의 사정이 없는 한 진료계약상의 의무 내지 침습 등에 대한 승낙을 얻기 위한 전제로서 당해 환자나 그 법정대리인에게 질병의 증상, 치료방법의 내용 및 필요성, 발생이 예상되는 위험 등에 관하여 당시의 의료수준에 비추어 상당하다고 생각되는 사항을 설명하여 당해 환자가 그 필요성이나 위험성을 충분히 비교해 보고 그 의료행위를 받을 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 48}}
{"id": "doc1_chunk49", "text": "필요성, 발생이 예상되는 위험 등에 관하여 당시의 의료수준에 비추어 상당하다고 생각되는 사항을 설명하여 당해 환자가 그 필요성이나 위험성을 충분히 비교해 보고 그 의료행위를 받을 것인가의 여부를 선택할 수 있도록 할 의무가 있”다고 한다.82) 우리나라의 판례는 두 단계로 설명의무 위반을 나누어 판단하는 것이 특징이다.83) 즉, ㉠ 위자료만 청구하는 경우와 ㉡ 모든 손해를 청구하는 경우를 두 단계로 구분하여, ㉠ 위자료만을 청구하는 경우에는 “의사의 설명결여 내지 부족으로 선택의 기회를 상실하였다는 사실만을 입증함으로써 족하고, 설명을 받았더라면 사망 등의 결과는 생기지 않았을 것이라는 관계까지 입증할 필요는 없”으나, ㉡ 그 결과로 인한 모든 손해를 청구하는 경우에는 “그 중대한 결과와 의사의 설명의무위반 내지 승낙취득과정에서의 잘못과의 사이에 상당인과관계가 존재하여야 하며, 그 경우 의사의 설명의무의 위반은 환자의 자기결정권 내지 치료행위에 대한 선택의 기회를 보호하기 위한 점에 비추어 환자의 생명, 신체에 대한 의료적 침습과정에서 요구되는 의사의 주의의무위반과 동일시할 정도의 것이어야 한다”고 한다.84) 이와 같은 설명의무에 관한 법리는 판례79) 신현호/백경희, 의료분쟁 조정·소송 총론, 육법사 2011, 277-282면.80)인폼드 컨센트(Informed Consent)에 대하여 자세한 내용은 최상회/윤종민, “인폼드 컨센트(Informed Consent)의 법리구조”, 「법학연구」, 제33집(2009), 112면 이하 참조.81)I. Glenn Cohen, Informed Consent and ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 49}}
{"id": "doc1_chunk50", "text": "센트(Informed Consent)의 법리구조”, 「법학연구」, 제33집(2009), 112면 이하 참조.81)I. Glenn Cohen, Informed Consent and Medical Artificial Intelligence: What to Tell the Patient?, 108 Geo. L.J. 1425(2020); Iñigo de Miguel, Begoña Sanz & Guillermo Lazcoz, Machine learning in the EU health care context: exploring the ethical, legal and social issues, 23 Info. Commc'n & Soc'y 1139 (2020); Maximilian Kiener, Artificial intelligence in medicine and the disclosure of risks, 36 AI & Soc. 705 (2021); Frank Ursin, Cristian Temmermann, Marcin Orzechowski & Florian Steger, Diagnosing Diabetic Retinopathy With Artificial Intelligence: What Information Should Be Included to Ensure Ethical Informed Consent?, 8 Frontiers in Medicine 1, 5 (2021); H. Benjamin Harvey & Vrushab Gowda, Clinical applications of AI in MSK imaging:", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 50}}
{"id": "doc1_chunk51", "text": "edicine 1, 5 (2021); H. Benjamin Harvey & Vrushab Gowda, Clinical applications of AI in MSK imaging: a liability perspective, 51 Skeletal Radiology 235, 236 (2022).82) 대법원 1995. 1. 20., 94다3421 판결83)이동진, “의사의 위험설명의무-법적 기능, 요건 및 위반에 대한 제재-”, 「의료법학」, 제21권 제1호(2020), 12면.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 235\n를 통하여 발전하여왔으나 2016년 의료법 개정을 통하여 명문의 규정을 두었다.85) 인공지능 의료기기를 활용하는 경우 언제, 어디까지 설명해야 하는지에 관한 문제는 위험설명의 범위와 관련된다. 판례는 위험설명의무 범위에 관하여 “질병의 증상, 치료방법의 내용 및 필요성, 발생이 예상되는 위험 등에 관하여 당시의 의료수준에 비추어 상당하다고 생각되는 사항을 설명하여 당해 환자가 그 필요성이나 위험성을 충분히 비교해 보고 그 의료행위를 받을 것인가의 여부를 선택할 수 있도록 하여야” 한다고 하고 있다.86) 또한 판례는 이러한 위험설명의무는 “그 의료행위에 따르는 후유증이나 부작용 등의 위험발생 가능성이 희소하다는 사정만으로 면제될 수 없으며, 그 후유증이나 부작용이 치료행위에 전형적으로 발생하는 위험이거나 회복할 수 없는 중대한 것인 경우에는 발생가능성의 희소성에도 불구하고 설명의 대상”이 된다고 한다.87) 즉 발생확률이 극히 낮더라", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 51}}
{"id": "doc1_chunk52", "text": "작용이 치료행위에 전형적으로 발생하는 위험이거나 회복할 수 없는 중대한 것인 경우에는 발생가능성의 희소성에도 불구하고 설명의 대상”이 된다고 한다.87) 즉 발생확률이 극히 낮더라도 결과가 중하거나 전형적인 위험에 대하여는 널리 설명의무를 인정하고 있다. 이렇게 위자료만 배상을 명하는 경우에 판례는 자기 결정에 중요한 요소가 아니었을 수 있는 위험에 대한 설명을 하지 않은 경우에까지 널리 설명의무 위반을 인정하고 있는데, 이는 의료과오책임에 관한 증명 곤란을 구제하기 위한 차선책으로 이해되고 있다.88) \n84)대법원 1995. 1. 20., 94다3421 판결; 심병연, “가. 의사가 환자에게 수술 등 침습을 가함에 있어 그 승낙을 얻기 위한 전제로서 부담하는 설명의무의 내용, 나. 설명의무위반과 손해배상의 범위”, 「대법원판례해설」, 통권 제21호(1994), 174면 이하. 여기서 주의의무위반과 동일시할 정도의 설명의무위반이란 설명을 하였더라면 달리 결정하였을 개연성이 매우 큰 경우를 말한다. 이동진, 위의 글, 6면.85)의료법 제24조의2에서는 의료인이 사람의 생명 또는 신체에 중대한 위해를 발생하게 할 우려가 있는 수술, 수혈, 전신마취를 하는 경우 환자에게 설명하고 서면 동의를 받아야 하는 사항을 정하고, 이에 위반하는 경우 300만원 이하의 과태료에 처하도록 하고 있다(의료법 제92조 제1항 제1의3호 및 제1의4호).제24조의2(의료행위에 관한 설명) ① 의사ㆍ치과의사 또는 한의사는 사람의 생명 또는 신체에 중대한 위해를 발생하게 할 우려가 있는 수술, 수혈, 전신마취(이하 이 조에서 “수술등", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 52}}
{"id": "doc1_chunk53", "text": "제24조의2(의료행위에 관한 설명) ① 의사ㆍ치과의사 또는 한의사는 사람의 생명 또는 신체에 중대한 위해를 발생하게 할 우려가 있는 수술, 수혈, 전신마취(이하 이 조에서 “수술등”이라 한다)를 하는 경우 제2항에 따른 사항을 환자(환자가 의사결정능력이 없는 경우 환자의 법정대리인을 말한다. 이하 이 조에서 같다)에게 설명하고 서면(전자문서를 포함한다. 이하 이 조에서 같다)으로 그 동의를 받아야 한다. 다만, 설명 및 동의 절차로 인하여 수술등이 지체되면 환자의 생명이 위험하여지거나 심신상의 중대한 장애를 가져오는 경우에는 그러하지 아니하다. ② 제1항에 따라 환자에게 설명하고 동의를 받아야 하는 사항은 다음 각 호와 같다. 1. 환자에게 발생하거나 발생 가능한 증상의 진단명 2. 수술등의 필요성, 방법 및 내용 3. 환자에게 설명을 하는 의사, 치과의사 또는 한의사 및 수술등에 참여하는 주된 의사, 치과의사 또는 한의사의 성명 4. 수술등에 따라 전형적으로 발생이 예상되는 후유증 또는 부작용 5. 수술등 전후 환자가 준수하여야 할 사항86) 대법원 1995. 1. 20., 94다3421 판결.87) 대법원 2004. 10. 28., 2002다45185 판결.88) 박태신, “의료소송에 있어서 설명의무의 기능”, 「연세법학연구」, 제5권 1호(1998), 596면.\n\n비교사법 제29권 4호(통권 제99호)\n236\n(나) 미국에서의 의사의 설명의무 또는 인폼드 컨센트(informed consent)미국에서는 의사는 합리적인 의사 또는 합리적인 환자를 기준으로 중요한(material) 정보를 공개하고 치료를 받", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 53}}
{"id": "doc1_chunk54", "text": "의사의 설명의무 또는 인폼드 컨센트(informed consent)미국에서는 의사는 합리적인 의사 또는 합리적인 환자를 기준으로 중요한(material) 정보를 공개하고 치료를 받을지 여부를 선택하도록 할 의무가 있다고 본다. 설명의무 위반으로 인한 책임은 일반 과실불법행위(negligence) 책임으로 이해하되, 설명의무 위반 이외에도 그 위험이 실현되었을 것(materialization of the risk)과 설명하였더라면 동의하지 않았을 것(decision causation)을 요구하고, 설명하지 아니한 위험이 실현되어 발생한 생명, 신체 침해 즉 전 손해에 대한 배상을 허용한다. 미국의 각 주들은 인폼드 컨센트 문제에 대한 접근방법에 관하여 환자 중심의 기준(patient-based standards)과 의사 중심의 기준(physician-based standards)로 나뉘어 있다. 환자 중심의 기준에 따르면, 의사가 보기에 환자의 입장에 있는 합리적인 사람이라면 해당 치료를 받을 것인지 여부를 결정하는 데 중요하다고 여길 만 한 위험을 고지하여야 한다.89) 의사 중심의 기준에 따르면, 합리적인 의료인이 동일한 또는 유사한 상황에서 고지하였을 내용을 설명하여야 한다.90)(다) 인공지능 의료기기를 활용한 경우 설명의무의 범위그렇다면 과연 인공지능 의료기기를 이용하여 진단에 도움을 받거나 치료 권고를 받는 경우에 이를 환자에게 설명해야 할까? 만약 그렇다면 어디까지 설명해야 할까? 미국의 인폼드 컨센트 법리에 따르면 합리적인 의사 또는 합리적인 환자를 기준으로 중요한 정보에 해당하는지가 판단 기준이", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 54}}
{"id": "doc1_chunk55", "text": "에게 설명해야 할까? 만약 그렇다면 어디까지 설명해야 할까? 미국의 인폼드 컨센트 법리에 따르면 합리적인 의사 또는 합리적인 환자를 기준으로 중요한 정보에 해당하는지가 판단 기준이 될 것인데, Cohen 교수는 지금까지 유사한 사례에서 적용된 판례 법리에 비추어 볼 때 환자에게 의료 인공지능을 사용하였음을 밝히지 않았다고 하여도 대부분의 경우에는 설명의무 위반이라고 볼 수 없을 것이라고 한다.91) 다만 1) 환자가 의사결정의 근거를 물었고, 의료 인공지능이 실제로 의사결정을 주도하였거나 주된 역할을 하였음에도 의사가 그렇지 않은 것처럼 설명한 경우, 2) 인공지능 의료기기가 (예컨대 더 많은 비용이 들지만 환자의 건강을 더욱 증진시킬 수 있는 선택지를 제외하는 방식으로) 환자의 이익에 반하는 방식으로 활용된 경우, 그리고 3) (예컨대 알고리즘이 불투명하여 설명가능하지 않음으로 인하여) 의사가 의료인공지능이 옳은 판단을 내렸다고 믿을 만한 합리적 근거가 없는 경우에는 설명의무 위반이 인정될 여지가 있을 것이라고 한다.92) 우리나라에서는 인공지능 의료기기 활용시 의사의 설명의무에 관하여, 인공지능 기술로 인하여 정보의 비대칭이 강화되는 점과 새로운 기술의 임상 적용에 따른 위험성을 고려하여 기술 사89)Canterbury v. Spence 464 F.2d 772, 776 (D.C. Cir. 1972) (requiring disclosure “when a reasonable person, in what the physician knows or should know to be the patient’s posit", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 55}}
{"id": "doc1_chunk56", "text": "sure “when a reasonable person, in what the physician knows or should know to be the patient’s positiion would be likely to attach significance to the risk or cluster of risks in deciding whether or not to forego the proposed therapy”).90)Natanson v. Kline 354 P.2d 670 (Kan. 1960) (mandating release of “the disclosures which a reasonable medical practitioner would make under the same or similar circumstances”).91)I. Glenn Cohen, Informed Consent and Medical Artificial Intelligence: What to Tell the Patient?, 108 Geo. L. J. 1425 (2020).92) Ibid.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 237\n용 여부, 내용, 방식에 대한 정보를 제공하는 등 더욱 강화된 설명이 필요하고 이에 대한 명시적이고 유효한 동의 확보가 필요하다는 견해가 있다.93) 왓슨의 진단조력과 관련하여 진단행위의 중요성과 왓슨의 사용이 아직 생소한 현실이라는 점을 감안하여 왓슨의 진단조력의 개입여부 및 그 불안전성에 대하여 환자에게 설명할 필요가 있다는 견해도 있다.", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 56}}
{"id": "doc1_chunk57", "text": "과 관련하여 진단행위의 중요성과 왓슨의 사용이 아직 생소한 현실이라는 점을 감안하여 왓슨의 진단조력의 개입여부 및 그 불안전성에 대하여 환자에게 설명할 필요가 있다는 견해도 있다.94) 위 견해들이 주장된 때에는 아직 우리나라 식약처의 정식 인증을 받은 인공지능 의료기기가 없을 때였다면, 이제는 매년 수십가지의 인공지능 의료기기가 시장에 새롭게 쏟아져 나오고 있다. 그런데 인공지능 의료기기의 오작동으로 인한 책임을 설명의무위반으로 구성하는 경우, 기존에 의료과오책임에 대한 증명곤란을 구제하기 위하여 위자료 배상을 명하는 경우 설명의무 위반을 널리 인정하던 우리나라의 기존의 판례의 태도가 그대로 유지된다면, 그래서 자기결정에 중요한 요소가 아닌 부분까지 의사의 설명의무를 널리 인정하게 되면, 의사의 책임 범위가 과도하게 넓어질 우려가 있다. 자칫 의사들이 인공지능 의료기기를 사용하기를 꺼리게 되는 결과를 피하기 위해서는 의사의 인공지능 의료기기 사용시 설명의무 범위와 관련한 명확한 가이드라인이 마련되어 책임에 관한 불확실성을 해소하여야 할 것이다. 이러한 가이드라인 마련을 위해서는 환자들이 해당 의료행위를 받을지 여부에 관한 의사결정을 하기 위해 어떤 정보를 필요로 하는지를 실증적으로 연구하고, 그 후에 이를 바탕으로 현실적으로 문제가 될 법한 시나리오에 따른 설명의무 범위에 대한 가이드라인을 준비하는 것이 바람직할 것이다. 나아가 이를 기초로 설명의무의 법리를 어떻게 적용하고 발전시켜나갈 것인지를 고민해야 한다. (3) 의료기관의 책임의사 개인보다는 상대적으로 자력이 충분한 의료기관을 상대로 책임을 묻는 것도", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 57}}
{"id": "doc1_chunk58", "text": "를 기초로 설명의무의 법리를 어떻게 적용하고 발전시켜나갈 것인지를 고민해야 한다. (3) 의료기관의 책임의사 개인보다는 상대적으로 자력이 충분한 의료기관을 상대로 책임을 묻는 것도 가능하다. 우선, 의료기관은 환자와 진료계약의 당사자이고, 진료를 담당하는 개개의 의료인은 이행보조자에 불과하므로, 의료사고와 같은 채무불이행이 발생하면 병원은 계약당사자로서 책임을 지게 된다.다음으로, 의료기관은 피용자인 의사의 사무집행에 관련한 불법행위에 대하여 사용자로서 손해를 배상할 책임을 질 수 있다.95) 미국의 사용자책임(respondeat superior) 법리에 따르더라도 사용자는 피용자가 그 고용 범위 내의 행위를 하다가 저지른 불법행위에 대하여 책임을 진다.96) 따라서 의료기관의 피용자인 의사가 인공지능 의료기기를 활용하여 환자에게 불법행위를 저질렀고, 그것이 피용자의 고용 범위 내의 행위였다면, 환자는 의료기관에 대하여 사용자책임을 물을 여지가 있을 것이다. 이와 같은 의료기관의 책임은 소위 대위책임에 해당한다.93) 배현아, 위의 글. 75-77면.94)장연화/백경희, “왓슨의 진단 조력에 대한 현행법상 형사책임에 관한 소고”, 「형사법의 신동향」, 제55호(2017), 337-338면. 95) 민법 제756조 제1항 본문.96)Restatement (Third) of Agency § 2.04 (2006) (“employer is subject to liability for torts committed by employees while acting within the scope of their employm", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 58}}
{"id": "doc1_chunk59", "text": "subject to liability for torts committed by employees while acting within the scope of their employment”).\n\n비교사법 제29권 4호(통권 제99호)\n238\n뿐만 아니라 의료기관은 자기 고유의 책임으로서 손해배상책임을 부담할 수도 있다. 즉, 의사를 적절히 고용, 관리, 감독할 의무를 위반하였다거나 또는 적합한 시설과 설비를 유지할 의무를 위반하였다는 이유로 의료기관 스스로의 과실로 인한 불법행위 책임을 질 수도 있을 것이다.97) 의료기관으로서는 안전성과 유효성을 갖춘 인공지능 의료기기를 검증하여 도입하고, 이를 제대로 활용하기 위하여 교육, 소프트웨어 업데이트, 지원 및 보수 등을 게을리 하지 않아야 할 의무를 진다고 볼 수 있기 때문이다.98) 만일 인공지능 의료기기를 공작물로 볼 수 있는 경우라면, 의료과오가 인공지능 의료기기의 설치 또는 보존상의 하자에 의하여 야기된 것인 경우 의료기관이 그 시설의 점유자 또는 소유자로서 무과실 손해배상책임을 질 여지가 있다.99) 여기서 말하는 공작물은 인공적으로 만들어진 설비를 말하는데, 병원 건물과 실질적으로 일체로 되어 있는 각종 의료설비, 예컨대 X선장치나 CT스캐너 등도 여기서 말하는 공작물이라고 할 수 있다.100) 그러나 인공지능 의료기기가 주로 그렇듯 소프트웨어의 형태를 띤다면, 이는 공작물로 볼 수 없으므로, 의료기관이 공작물의 점유자 또는 소유자로서 책임을 부담할 가능성은 없다.101)다만 인공지능 의료기기가 완전히 자동화(fully autonomous)되거나, 인공", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 59}}
{"id": "doc1_chunk60", "text": "볼 수 없으므로, 의료기관이 공작물의 점유자 또는 소유자로서 책임을 부담할 가능성은 없다.101)다만 인공지능 의료기기가 완전히 자동화(fully autonomous)되거나, 인공지능 의료기기를 구매하고 사용하는 의료기관이나 의사보다는 이를 설계하고 제작한 제조업자의 관리 하에 있다고 볼 수 있게 되는 경우에는 인공지능 의료기기로 인하여 환자가 입은 손해에 관하여 의료기관에 그 과실에 근거한 책임(즉 의사의 과실을 전제로 한 사용자책임 또는 의료기관 고유의 과실에 기한 책임)을 묻는 것은 어려워질 수도 있다. 의료기관의 통제를 벗어나는 영역이라고 볼 수 있기 때문이다.102) 그렇다면 이러한 경우에는 인공지능 의료기기 제조업자에게 책임을 물을 수 있을 것인가?\n97)Price II, 위의 글, 303, 304면. 미국의 의료기관의 직접 책임에 관한 법리는, Mark A. Hall et al., Health Care Law and Ethics (Wolters Kluwer 2018) 445 참조. 우리나라에서도 병원은 조직편성상의 과실로 인한 불법행위 책임을 질 여지가 있다는 것은, 주호노, 위의 책, 860~861면 참조.98) Maliha, et al., 위의 글.99)민법은 공작물의 설치 또는 보존의 하자로 인하여 타인에게 손해를 가한 때에는 공작물점유자가 손해를 배상할 책임이 있다고 하고, (민법 제758조 제1항 본문), 점유자가 손해의 방지에 필요한 주의를 해태하지 아니한 때에는 그 소유자가 손해를 배상할 책임이 있다고 규정하고 있다(민법 제758조 제1항 단서).100) 주호노, 위의 책, 859면.", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 60}}
{"id": "doc1_chunk61", "text": "가 손해의 방지에 필요한 주의를 해태하지 아니한 때에는 그 소유자가 손해를 배상할 책임이 있다고 규정하고 있다(민법 제758조 제1항 단서).100) 주호노, 위의 책, 859면.101) 이중기/이재현, 위의 글, 273면. 102)Scott J. Schweikart, Who Will Be Liable for Medical Malpractice in the Future? How the Use of Artificial Intelligence in Medicine Will Shape Medical Tort Law?, 22 Minnesota Journal of Law, Science & Technology 1, 16 (2021).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 239\n4. 인공지능 의료기기 제조업자의 책임인공지능 의료기기의 제조업자에게 제조물책임을 묻는 데에는 여러 가지 난관들이 존재한다. 제조물책임을 묻기 위해서는 일단 제조물에 해당해야 하는데103) 소프트웨어를 제조물로 볼 수 있는지에 관하여 논란이 있다. 제조물책임법 제2조 제1호에 따르면, “제조물”이란 제조되거나 가공된 동산을 말한다.104) 동산은 부동산 이외의 물건을 의미하므로,105) 소프트웨어를 제조물로 볼 수 있는지의 문제는 소프트웨어를 물건, 즉 “유체물 전기 기타 관리할 수 있는 자연력”에 포함된다고 볼 수 있는지의 문제가 된다.106) 미국에서도 소프트웨어를 서비스(service)가 아닌 제조물(product)로 볼 수 있는지에 대하여 마찬가지로 논란이 있고, 특히 SaMD(S", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 61}}
{"id": "doc1_chunk62", "text": " 수 있는지의 문제가 된다.106) 미국에서도 소프트웨어를 서비스(service)가 아닌 제조물(product)로 볼 수 있는지에 대하여 마찬가지로 논란이 있고, 특히 SaMD(Software as a medical device)와 같은 소프트웨어의 경우 제조물책임이 적용될 수 있는지 여부에 관하여는 아직 한국이나 미국 어디에서도 논란이 정리되지 않았다.107)제조물 책임을 물으려면 결함이 인정되어야 하는데, 우리 법은 제3차 미국 불법행위법 리스테이트먼트의 영향을 받아 제조상 결함, 설계상 결함, 표시상 결함의 세 유형을 구분하고 있다. 우선 제조상 결함은 원래 의도한 설계와 다르게 제조·가공된 결함을 말한다. 가장 빈번하게 문제되는 유형의 결함은 아무래도 제조업자가 합리적인 대체설계를 채용하지 않아 안전성을 결여하게 된 경우에 해당하는 설계상 결함이 될 가능성이 높다. 그러나 인공지능 의료기기의 경우 그 작동방식을 이해하는 것도 쉽지 않은 점을 고려하면, 합리적 대체설계의 존재를 증명한다는 것은 환자 입장에서 매우 어려울 것으로 보인다. 세 번째 결함 유형은 합리적인 설명, 지시, 경고 등 기타 표시를 했다면 당해 제조물에 의해 발생할 피해나 위험을 줄이거나 피할 수 있었을 경우에 인정되는 표시상 결함이다. 이와 관련하여 제조업자는 인공지능 의료기기를 사용하기로 결정한 의사에게 적절한 지시, 설명, 경고를 한 것으로 의무를 다하였다고 주장할 수 있는데, 이처럼 의료기기 제조업자에 대한 책임을 제한하는 것이 바로 ‘지식을 가진 중간자 이론(Learned intermediary doctrine)’이다.108)", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 62}}
{"id": "doc1_chunk63", "text": "다고 주장할 수 있는데, 이처럼 의료기기 제조업자에 대한 책임을 제한하는 것이 바로 ‘지식을 가진 중간자 이론(Learned intermediary doctrine)’이다.108) 의료기기의 제조103)제조물책임법 제3조(제조물 책임) ① 제조업자는 제조물의 결함으로 생명ㆍ신체 또는 재산에 손해(그 제조물에 대하여만 발생한 손해는 제외한다)를 입은 자에게 그 손해를 배상하여야 한다.104) 제조물책임법 제2조(정의) 이 법에서 사용하는 용어의 뜻은 다음과 같다. 1. “제조물”이란 제조되거나 가공된 동산(다른 동산이나 부동산의 일부를 구성하는 경우를 포함한다)을 말한다.105) 민법 제99조 제2항.106) 민법 제98조(물건의 정의) 본법에서 물건이라 함은 유체물 및 전기 기타 관리할 수 있는 자연력을 말한다.107)소프트웨어가 지금까지 제조물(product) 보다는 서비스로 해석되고 있다는 점에 대하여는, Barbara J. Evans & Frank Pasquale, Product Liability Suits for FDA-Regulated AI/ML Software in I. Glenn Cohen et al. (eds), The Future of Medical Device Regulation: Innovation and Protection (Cambridge University Press, 2022); Michael D. Scott, Tort Liability for Vendors of Insecure Software: Has the Time Finally Come, 67 Md. L. Rev. 425, ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 63}}
{"id": "doc1_chunk64", "text": "tt, Tort Liability for Vendors of Insecure Software: Has the Time Finally Come, 67 Md. L. Rev. 425, 436-42 (2007); Frances E. Zollers et al., No More Soft Landings for Software: Liability for Defects in an Industry That Has Come of Age, 21, Santa Clara Computer & High Tech. L.J. 745 (2004). 108)Timothy Hall, Reimagining the Learned Intermediary Rule for the New Pharmaceutical Marketplace, 35 Seton \n\n비교사법 제29권 4호(통권 제99호)\n240\n업자와 환자 사이에 의사가 끼어있기 때문에 의사를 최종 소비자로 보고, 제조업자로서는 의사에 대하여 지시·경고 의무를 다하는 것으로 충분하다는 것이다. 따라서 의사에게 이러한 의무를 다한 경우 환자가 직접 의료기기 제조업자에 대한 제조물책임을 묻기는 어려워질 것이다. 마지막으로 연방제도를 택하고 있는 미국법에는 의료기기 제조업자에 대한 제조물책임을 묻는 데에 특유한 난관이 있다. 미연방헌법 제6조 2문의 연방법 우위 조항(the Supremacy Clause)에서 파생한 연방법 우선적용이론(Preemption doctrine)이다.109) 1976년 미국 식품의약품화장품법(FDCA)에 대한 의료기기 개정법(Medical Devices Amendments)에", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 64}}
{"id": "doc1_chunk65", "text": "선적용이론(Preemption doctrine)이다.109) 1976년 미국 식품의약품화장품법(FDCA)에 대한 의료기기 개정법(Medical Devices Amendments)에서 명시적으로 주법에서 연방법에서 정하는 조건과 다른 조건을 정하거나 추가하는 것을 금지한다고 정하여서 의료기기에 대한 연방법의 우위를 인정하였다.110) 2008년 Riegel v. Medtronic, Inc에서 미국 대법원은 주법에 따른 PMA 절차를 거친 의료기기에 관한 불법행위 청구는 연방법 우선적용대상이어서 허용되지 않는다고 판단하였고,111) 한편 1996년 Medtronic, Inc. v. Lohr 판결에서는 PMA보다 완화된 501(k) 절차를 거친 의료기기에 관한 불법행위 주장은 연방법 우선적용대상이 되지 않는다고 판단한 바 있다.112) 이 두 사안에서 결론이 달라지게 된 결정적인 이유는, PMA 절차를 거쳐 시판된 의료기기에 관한 불법행위 청구는 필연적으로 증거에 기반한 위험효용 분석(evidence-based risk-benefit analysis)의 반복을 초래하게 되는 반면, 완화된 501(k) 절차를 거쳐 시판된 의료기기의 경우에는 그렇지 않다는 데 있었다.113)법조문과 일련의 판례들에 비추어 일반적으로 다음 세 가지의 경우 연방법 우선적용 원칙(preemption doctrine)의 예외로 본다. 첫째, 가장 엄격한 시판전 허가절차인 PMA 절차를 거쳐 시Hall L. Rev. (2005). 우리나라에서 ‘지식을 가진 중간자 이론(learned intermediary doctrine)’에 터잡아 의료기기", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 65}}
{"id": "doc1_chunk66", "text": "절차인 PMA 절차를 거쳐 시Hall L. Rev. (2005). 우리나라에서 ‘지식을 가진 중간자 이론(learned intermediary doctrine)’에 터잡아 의료기기 제조업자의 책임을 제한할 수 있을 것인지에 대한 논의는 아직 활발하지 않으나, 같은 논리가 적용될 수 있을 것으로 보인다. 109)인공지능 의료기기와 관련한 FDA의 규제와 제조업자의 책임 사이의 연방법 우선적용이론(preemption doctrine)을 둘러싼 긴장관계에 관하여는, Evans & Pasquale, 위의 글; Charlotte A. Tschider, Medical Device Artificial Intelligence: The New Tort Frontier, 46 BYU L. Rev. 1551 (2021). 110) Medical Device Amendments of 1976, 21 U.S.C. § 360k(a)[N]o state . . . may establish or continue in effect with respect to a device intendedfor human use any requirement—(1) which is different from, or in addition to, any requirement applicable under this chapter to the device, and(2) which relates to the safety or effectiveness of the device or to any other matter included in a requirement app", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 66}}
{"id": "doc1_chunk67", "text": "es to the safety or effectiveness of the device or to any other matter included in a requirement applicable to the device under this chapter.이와 같은 명시적 선점(explicit preemption) 외에도 주 입법을 적용하는 것이 연방법과 충돌하는 경우에는 해석을 통한 묵시적 선점(implicit preemption)도 인정될 수 있다. 김장한, “의료기기의 결함으로 인한 손해배상책임과 미국 연방법 우선 적용 이론에 관하여”, 의료법학(제15권 제2호), 대한의료법학회(2014), 74-75면.111) Riegel v. Medtronic, Inc., 552 U.S. 312 (2008).112) Medtronic, Inc. v. Lohr, 518 U.S. 470, 471 (1996).113)Robert L. Rabin & Alyssa J. Picard, Reassessing the Regulation of High-Risk Medical Device Cases, 68 DePaul L. Rev. 309, 322-23 (2019); Robert L. Rabin, Territorial Claims in the Domain of Accident Law: Conflicting Conceptions of Tort Preemption, 74 Brook L. Rev. 987, 995 (2009).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 241\n판된 의료기기의", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 67}}
{"id": "doc1_chunk68", "text": " 74 Brook L. Rev. 987, 995 (2009).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 241\n판된 의료기기의 경우에만 Riegel 판결이 적용되어 주법에 근거한 불법행위 청구에 대하여 연방법 우선적용의 항변(preemption defense)을 행사할 수 있다. 둘째, “parallel actions” 즉 주법에 기한 불법행위 청구가 연방법 위반에 근거한 것인 때에는 새로운 조건을 추가하는 것이 아니기 때문에 연방법 우선적용 원칙의 적용을 받지 않는다.114) 마지막 예외는 PMA 허가 이후에 새로운 중요한 증거가 나온 경우이다.115) 규제 당국의 허가가 있은 후에 의료기기와 관련한 위험에 대한 새로운 증거가 발견되고 이에 기초한 불법행위 청구가 이루어진 경우라면 규제당국의 허가 당시에 이루어진 증거에 기반한 결정을 재검토할 필요가 없기 때문이다.116)미국 법원은 지금까지 의사결정 보조 도구(decision support tool)로 여겨지는 의료 소프트웨어의 제조업자에게 제조물책임을 인정하는 데에 대체로 소극적이었다.117) 우리나라에서도 아직 의료 소프트웨어 제조업자를 상대로 한 제조물책임 소송이 제기되었음은 알려진 바 없다.118) 다만, 향후 인공지능, 특히 그 작동방식을 이해하기 힘든 블랙박스와 같은 딥러닝 알고리즘이 의료에 널리 쓰이게 될 경우에 대비하여 인공지능 소프트웨어 의료기기에 대하여 제조물책임 법리의 확장, 적용이 필요한지에 대한 진지한 검토가 요청된다. 5. 보험 등을 통한 위험의 이전지금까지 인공지능 의료기기의 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 68}}
{"id": "doc1_chunk69", "text": "비하여 인공지능 소프트웨어 의료기기에 대하여 제조물책임 법리의 확장, 적용이 필요한지에 대한 진지한 검토가 요청된다. 5. 보험 등을 통한 위험의 이전지금까지 인공지능 의료기기의 오작동으로 인한 의사, 의료기관 및 인공지능 의료기기 제조업자의 책임을 살펴보았는데, 이들이 부담하는 위험을 분산하는 데에는 보험이 큰 역할을 할 수 있다. 인공지능 의료기기의 오작동으로 인한 위험의 분배에 보험의 역할도 빼놓을 수 없다. 의사나 의료기관은 의료배상책임보험에 가입함으로써 위험을 분산하려 할 수 있다. 한편 의료기기 제조업자 및 수입업자에 대하여는 최근 의료기기법 개정으로 책임보험 가입이 의무화되었다.119) 또한 위험의 분담 또는 이전은 보험 뿐만 아니라 계약을 통하여, 예컨대 병원과 의사 사이에 혹은 의료기기 제조업체와 병원 사이에서 이루어질 수도 있다. 실제로 소프트웨어 제조업자들은 의료기관과의 이용허락계약(license terms)을 통하여 책임을 이전하거나 면책을 요구하곤 한다.120) 114)Riegel 재판의 다수의견은 명시적으로 이러한 경우 연방법상 요건에 추가하는 것이 아니라 평행한(parallel) 것이므로 연방법 우선적용 원칙의 적용을 받지 않는다고 명확히 하였다. Riegel, 128 S. Ct. at 1011. 115) Riegel, 128 S. Ct. at 1013.116) Rabin et al, 위의 글, 315-16.117)Price, W. Nicholson, II. Artificial Intelligence in Health Care: Applications and Legal Implica", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 69}}
{"id": "doc1_chunk70", "text": ".117)Price, W. Nicholson, II. Artificial Intelligence in Health Care: Applications and Legal Implications, 14 The SciTech Lawyer 1, 11-12 (2017).118)2010년까지 우리나라의 의료기기 결함으로 인한 대표적인 제조물책임소송은 2002년 제조물책임법 제정 전의 것들이었다. 김상찬, “의료기기의 결함과 제조물책임”, 「법학연구」, 제39집(2010), 54-55면.119)의료기기법 제43조의6(보험가입 등) ① 대통령령으로 정하는 의료기기 제조업자ㆍ수입업자는 의료기기를 사용하는 도중에 발생한 사망 또는 중대한 부작용 등으로 인하여 환자에게 발생한 피해를 배상하기 위하여 보험 또는 공제에 가입하여야 한다. ② 제1항에 따른 보험 또는 공제의 종류, 가입 대상, 보험금액 및 그 밖에 필요한 사항은 대통령령으로 정한다. (시행일: 2022. 7. 21.)\n\n비교사법 제29권 4호(통권 제99호)\n242\n예컨대, 전자의무기록(electronic health record, EHR) 시스템에 관한 공급계약에는 대체적 분쟁해결절차와 안전성 문제에 대한 비밀유지조항(gag clause)과 함께 이러한 책임 이전에 관한 조항이 포함되어 있다.121) 6. 공동사업책임(common enterprise liability) 또는 기금 등을 통한 특별보상제도인공지능 의료기기의 특수성을 고려한 새로운 배상체계를 구상하는 견해도 제시되고 있다. 인공지능의 불투명성(opacity)에도 불구하고 인공지능의 오작동으로 인한 책임을 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 70}}
{"id": "doc1_chunk71", "text": "특별보상제도인공지능 의료기기의 특수성을 고려한 새로운 배상체계를 구상하는 견해도 제시되고 있다. 인공지능의 불투명성(opacity)에도 불구하고 인공지능의 오작동으로 인한 책임을 묻기 위하여 과실을 입증하도록 요구하는 것은 부적절하다거나122) 인공지능 의료기기의 가소성(plasticity) 이라는 특수한 성격을 고려하면 기존의 분쟁해결제도가 적절하지 않다는 지적이 있다.123) 이러한 이유로 인공지능 의료기기를 위한 새로운 배상체계를 구상하는 견해들이 제시되고 있다. 우선, 의사, 인공지능 의료기기 제조업자, 인공지능 의료기기를 채택한 의료기관이 불법행위로 인한 책임에 관하여 공동 사업 책임(common enterprise liability)을 져야 한다는 견해가 있다.124) 이를 통해 인공지능 기술이 임상에 도입되면서 발생할 수 있는 책임의 공백을 줄이고 피해회복을 도모함과 아울러 관련된 이해관계자들이 주의의무를 다할 강력한 유인을 제공할 수 있다는 것이다.125)다음으로 입법을 통하여 인공지능 의료기기로 인한 피해에 대하여 무과실 보상제도를 도입하고 의료기기회사로부터 부담금을 걷어 기금을 마련하여 이를 통해 피해를 구제하는 방안도 생각해 볼 수 있다. 예컨대 미국의 백신보상제도는 백신 제조업체들이 기금을 조성하여 백신 피해자들이 보상을 받을 수 있도록 함으로써 위험을 분산하는 제도이다.126) 우리나라의 의약품에 관하여 식품의약품안전처 산하의 한국의약품안전관리원의 보상제도도 기금방식의 무과실보상제도 형식을 취하고 있다.127) 다만 이러한 제도를 채택할 경우 개별 제조업자들이 제품의 안전성을 향120)", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 71}}
{"id": "doc1_chunk72", "text": "약품안전처 산하의 한국의약품안전관리원의 보상제도도 기금방식의 무과실보상제도 형식을 취하고 있다.127) 다만 이러한 제도를 채택할 경우 개별 제조업자들이 제품의 안전성을 향120) Evans 10.121)Jim Hawkins, Barbara Evans, Harlan Krumholz, Nontransparency in Electronic Health Record Systems, in Transparency in Health and Health Care in the United States 273-85 (Holly F. Lynch, I. Glenn Cohen, Carmel Shachar, Barbara J. Evans eds., 2019). 122) Andrew D. Selbst, Negligence and AI’s human users, 100 B. U. L. Rev. 1315 (2020).123) Boris Babic et al,, 각주 46, 위의 글.124)Chan, 위의 글. 자율주행 자동차의 부품 제조업자들에게도 완성품 제조업자들과 함께 공동 사업 책임(common enterprise liability)을 부과하여야 한다는 주장으로는, David Vladeck, Machines Without Principals: Liability Rules and Artificial Intelligence, 89 Wash. L. Rev. 117, 129 n.39 (2014).125) Chan, 위의 글.126)Sara Gerke, Timo Minssen & Glenn Cohen, Ethical and legal cha", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 72}}
{"id": "doc1_chunk73", "text": "7, 129 n.39 (2014).125) Chan, 위의 글.126)Sara Gerke, Timo Minssen & Glenn Cohen, Ethical and legal challenges of artificial intelligence-driven healthcare, in Artificial intelligence in Healthcare 314 (Adam Bohr & Kaveh Memarzadeh eds., 2020)..127)최철호, “우리나라 의료기기 부작용에 따른 피해구제시스템 도입방안 연구”, 「한국의료법학회지」, 제25권 제2호(2017), 52면.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 243\n상시킬 인센티브가 줄어들 우려가 있다.128)\nⅣ. 마치며지금까지 우리나라와 미국을 중심으로 인공지능 의료기기와 관련한 규제법적, 책임법적 이슈들을 조망하고, 향후 연구와 토론이 필요한 문제들을 짚어보았다. 우선 인공지능 의료기기의 규제와 관련하여, 특히 기계학습 의료기기의 소위 업데이트 문제(update problem)에 어떻게 대응할 것인지 및 인공지능 의료기기에 대한 보험수가 책정에 관한 문제가 당장 풀어야 할 숙제이다. 다음으로, 인공지능 의료기기의 오작동으로 인한 책임 문제에 관하여, 의사의 주의의무 기준 및 설명의무 범위에 대한 구체적인 가이드라인 마련을 위한 이론적, 실증적 연구가 필요하다. 또한 인공지능 의료기기의 성능이 점점 향상될수록 소프트웨어 의료기기 제조업자의 제조물책임 인정과 관련한 논의 및 기금 등을 통한 특별보상제도 또", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 73}}
{"id": "doc1_chunk74", "text": " 이론적, 실증적 연구가 필요하다. 또한 인공지능 의료기기의 성능이 점점 향상될수록 소프트웨어 의료기기 제조업자의 제조물책임 인정과 관련한 논의 및 기금 등을 통한 특별보상제도 또는 특별한 분쟁해결절차의 마련의 필요성에 관한 논의가 더욱 필요하게 될 것으로 보인다. 인공지능 의료기기와 관련하여 지금까지의 법적 논의를 정리하고 앞으로 더욱 연구와 논의가 필요한 쟁점을 소개하는 이 글이 이 분야의 활발한 연구와 이해관계자들의 토론을 촉발하는 계기가 되기를 기대해 본다. ∙투 고 일:2022년 11월 03일∙심 사 일:2022년 11월 10일∙게재확정일:2022년 11월 24일\n128) Gerke, et al., 위의 글.\n\n비교사법 제29권 4호(통권 제99호)\n244\n[참고문헌][국내문헌][단행본]이상돈/김나경, 의료법강의(제4판), 법문사, 2020, 129-130면.신현호/백경희, 의료분쟁 조정·소송 총론, 육법사, 2011, 277-282면.[논문]김광수, 인공지능 기반 과학기술과 국민의 권익구제-자율주행차, 드론 및 의료기기를 중심으로-, 토지공법연구, 제85집, 2019.김병관/양석조, 임상적 관점에서의 의료기기 관리제도 개선방안 연구, 과학기술법연구, 제25집 제4호, 2019.김상찬, 의료기기의 결함과 제조물책임, 법학연구, 제39집, 2010.김재선, 인공지능 의료기기 위험관리를 위한 규범론적 접근-인공지능 소프트웨어 규범화 논의를 중심으로-, 공법연구, 제46집 제2호, 2017.엄주희/김소윤, 인공지능 의료와 법제, 한국의료법학회지, 제28권 제2호, 2020.김재완, 로봇수술로 인한 의료과오", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 74}}
{"id": "doc1_chunk75", "text": "범화 논의를 중심으로-, 공법연구, 제46집 제2호, 2017.엄주희/김소윤, 인공지능 의료와 법제, 한국의료법학회지, 제28권 제2호, 2020.김재완, 로봇수술로 인한 의료과오 민사책임에 있어 과실 판단의 문제, 아주법학, 제14권 제1호, 2020.박정연, 의료기기 진입규제의 변화: 공법적 정당화 논거와 규제 방향성, 법학논총, 제46집, 2020.박태신, 의료소송에 있어서 설명의무의 기능, 연세법학연구, 제5권 1호, 1998.배현아, 보건의료법제 하에서 인공지능기술의 의료영역 도입의 의의와 법적 문제, 법조, 제724집, 2017.백경희/장경화, 인공지능을 이용한 의료행위와 민사책임에 관한 고찰, 법조, 제724집, 2017.백경희/장연화, 의료판례의 동향과 문제: 민사법적 쟁점과 전망을 중심으로, 한국의료법학회지, 제26권 제1호, 2018.석희태, 의료과실 판단기준에 관한 학설·판례의 동향, 의료법학, 제1권 제1호, 2000.설민수, 머신러닝 인공지능과 인간전문직의 협업의 의미와 법적 쟁점: 의사의 의료과실 책임을 사례로, 저스티스, 제163호, 2017.손승호 외 4인, 빅데이터 및 인공지능 기술 적용 의료기기의 허가심사 방안, 대한전자공학회 학술대회 논문집, 2018.심병연, 가. 의사가 환자에게 수술 등 침습을 가함에 있어 그 승낙을 얻기 위한 전제로서 부담하는 \n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 245\n설명의무의 내용, 나. 설명의무위반과 손해배상의 범위, 대법원판례해설, 통권 제21호, 1994.이동진, 의사의 위험설명의무-법", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 75}}
{"id": "doc1_chunk76", "text": " 진화 및 책임의 배분을 중심으로|박혜진|\n 245\n설명의무의 내용, 나. 설명의무위반과 손해배상의 범위, 대법원판례해설, 통권 제21호, 1994.이동진, 의사의 위험설명의무-법적 기능, 요건 및 위반에 대한 제재-, 의료법학, 제21권 제1호, 2020.이인영, 보건의료에서의 인공지능 적용과 관련된 법적 과제에 대한 개관, 한국의료법학회지제27권 제2호, 2019.이중기/이재현, 의료 AI에 대한 규제체제와 책임의 귀속-진단AI와 수술로봇을 중심으로-, 홍익법학, 제21권 제4호, 2020.장연화/백경희, 왓슨의 진단 조력에 대한 현행법상 형사책임에 관한 소고, 형사법의 신동향, 제55호, 2017.정채연, 의료 인공지능의 법적 수용을 위한 시론적 연구, 법학논총, 제45권 제3호, 2021.최상회/윤종민, 인폼드 컨센트(Informed Consent)의 법리구조, 법학연구, 제33집, 2009.최철호, 우리나라 의료기기 부작용에 따른 피해구제시스템 도입방안 연구, 한국의료법학회지, 제25권 제2호, 2017.[기타자료]건강보험심사평가원, 혁신적 의료기술의 요양급여 여부 평가 가이드라인-AI 기반 병리학 분야, 2020.보건복지부/건강보험심사평가원, 혁신적의료기술의 요양급여여부 평가 가이드라인-AI기반 의료기술(병리학분야), 2020.보건복지부/건강보험심사평가원, 혁신적의료기술의 요양급여여부 평가 가이드라인-AI기반 의료기술(영상의학분야) & 3D 프린팅 이용 의료기술, 2019.식품의약품안전처, 2022. 5. 12.자 보도자료, 2022. 식품의약품안전처, 빅데이터 및 인공지능(AI) 기술이 적용된 의", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 76}}
{"id": "doc1_chunk77", "text": "의학분야) & 3D 프린팅 이용 의료기술, 2019.식품의약품안전처, 2022. 5. 12.자 보도자료, 2022. 식품의약품안전처, 빅데이터 및 인공지능(AI) 기술이 적용된 의료기기의 허가·심사 가이드라인(민원인 안내서), 2017.식품의약품안전처, 첨단의료기기 단계별 허가심사 가이드라인, 2016.대법원 1988. 12. 13., 85다카1491 판결.대법원 1994. 4. 15., 93다60953 판결.대법원 1995. 1. 20., 94다3421 판결대법원 1999. 3. 26., 98다45379, 45386 판결.대법원 2004. 10. 28., 2002다45185 판결.대법원 2017. 2. 15., 2014다230535 판결.\n\n비교사법 제29권 4호(통권 제99호)\n246\n[외국문헌][단행본]American Law Institute, Restatement (Third) of Agency, American Law Institute Publishers, (2006).Mark A. Hall et al., Health Care Law and Ethics, Wolters Kluwer, (2018).[논문]A. Michael Froomkin, Ian Kerr & Joelle Pineau, When AIs Outperform Doctors: Confronting the Challenges of a Tort-Induced Over-Reliance on Machine Learning, 61 Ariz. L. Rev. 33, 52-54 (2019)Andrew D. Selbst, Negligence and AI’s", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 77}}
{"id": "doc1_chunk78", "text": "Reliance on Machine Learning, 61 Ariz. L. Rev. 33, 52-54 (2019)Andrew D. Selbst, Negligence and AI’s Human Users, 100 B.U. L. Rev. 1315 (2020)Barbara J. Evans & Frank Pasquale, Product Liability Suits for FDA-Regulated AI/ML Software in I. Glenn Cohen et al. (eds), The Future of Medical Device Regulation: Innovation and Protection (Cambridge University Press, 2022).Benny Chan, Applying a Common Enterprise Theory of Liability to Clinical AI Systems, 47 Am. J. L. & Med. 351, 369 (2021).Boris Babic et al., Beware Explanation from AI in Healthcare, 373 Science 284 (2021). Boris Babic, Sara Gerke, Theodoros Evgeniou & I. Glenn Cohen, Algorithms on regulatory lockdown in medicine, 366 Science 1202 (2019). Charlotte A. Tschider, Medical Device Art ㅜificial Intelligence: The New Tort Frontier, 46 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 78}}
{"id": "doc1_chunk79", "text": " (2019). Charlotte A. Tschider, Medical Device Art ㅜificial Intelligence: The New Tort Frontier, 46 BYU L. Rev. 1551 (2021).David Vladeck, Machines Without Principals: Liability Rules and Artificial Intelligence, 89 Wash. L. Rev. 117 (2014).Frances E. Zollers et al., No More Soft Landings for Software: Liability for Defects in an Industry That Has Come of Age, 21, Santa Clara Computer & High Tech. L.J. 745 (2004).Frank Griffin, Artificial Intelligence and Liability in Health Care, 31 Health Matrix 65 (2021).Frank Ursin, Cristian Temmermann, Marcin Orzechowski & Florian Steger, Diagnosing Diabetic Retinopathy With Artificial Intelligence: What Information Should Be Included to Ensure Ethical Informed Consent?, 8 Frontiers in Medicine 1, 5(2021)George Maliha, Sara Gerke, I. Glenn Cohen & Rav", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 79}}
{"id": "doc1_chunk80", "text": "Informed Consent?, 8 Frontiers in Medicine 1, 5(2021)George Maliha, Sara Gerke, I. Glenn Cohen & Ravi B. Parikh, Artificial Intelligence and Liability in Medicine: Balancing Safety and Innovation, 99 The Milbank Quarterly 629 (2021).H. Benjamin Harvey & Vrushab Gowda, Clinical applications of AI in MSK imaging: a liability \n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 247\nperspective, 51 Skeletal Radiology 235 (2022).I. Glenn Cohen, Informed Consent and Medical Artificial Intelligence: What to Tell the Patient?, 108 Geo. L.J. 1425 (2020)Iñigo de Miguel, Begoña Sanz & Guillermo Lazcoz, Machine learning in the EU health care context: exploring the ethical, legal and social issues, 23 Info. Commc'n & Soc'y 1139 (2020).Jim Hawkins, Barbara Evans, Harlan Krumholz, Nontransparency in Ele", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 80}}
{"id": "doc1_chunk81", "text": "nfo. Commc'n & Soc'y 1139 (2020).Jim Hawkins, Barbara Evans, Harlan Krumholz, Nontransparency in Electronic Health Record Systems, in Transparency in Health and Health Care in the United States 273-85 (Holly F. Lynch, I. Glenn Cohen, Carmel Shachar & Barbara J. Evans eds., 2019). Kevin Tobia, Aileen Nielsen & Alexander Stremitzer, When Does Physician Use of AI Increase Liaiblity?, 62 J. Nuclear Med. 17 (2021)Khalifa et al., Developing a framework for evidence-based grading and assessment of predictive tools for clinical decision support, 19 BMC Med Inform Decis Mak. 1 (2019).Latrice G. Landry, Heidi L. Rehm, Association of Racial/Ethnic Categories with the Ability of Genetic Tests to Detect a Cause of Cardiomyopathy, 3 JAMA Cardiol 341 (2018)Lawrence B. Solum, Legal Personhood for Artifici", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 81}}
{"id": "doc1_chunk82", "text": "a Cause of Cardiomyopathy, 3 JAMA Cardiol 341 (2018)Lawrence B. Solum, Legal Personhood for Artificial Intelligence, 70 N.C. L. Rev. 1231 (1992)Maximilian Kiener, Artificial intelligence in medicine and the disclosure of risks, 36 AI & Soc. 705 (2021)Maxwell J. Mehlman, Medical practice guidelines as malpractice safe harbors: illusion or deceit?, 40 J. L., Med. & Ethics 286 (2012).Michael D. Scott, Tort Liability for Vendors of Insecure Software: Has the Time Finally Come, 67 Md. L. Rev. 425 (2007); Michael Frakes, The Impact of Medical Liability Standards on Regional Variations in Physician Behavior: Evidence from the Adoption of National-Standard Rules, 103 Am. Econ. Rev. 257 (2013).Michelle M. Mello, Of Swords and Shields: The Role of Clinical Practice Guidelines in Medical Malpractice ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 82}}
{"id": "doc1_chunk83", "text": "le M. Mello, Of Swords and Shields: The Role of Clinical Practice Guidelines in Medical Malpractice Litigation, 149 U. Penn. L. Rev. 645 (2001).Philipp Hacker, Ralf Krestel, Stefan Grundmann & Felix Naumann, Explainable AI under contract and tort law: legal incentives and technological challenges, 28 Artificial Intelligence and Law 415, 421-423 (2020).Robert F. Wolff et al., PROBAST: a tool to assess the risk of bias and applicability of prediction model studies, 170 Annals of internal medicine 51 (2019).Robert L. Rabin & Alyssa J. Picard, Reassessing the Regulation of High-Risk Medical Device Cases, 68 DePaul L. Rev. 309 (2019).Robert L. Rabin, Territorial Claims in the Domain of Accident Law: Conflicting Conceptions of Tort \n\n비교사법 제29권 4호(통권 제99호)\n248\nPreemption, 74 Brook L. Rev. 987 (20", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 83}}
{"id": "doc1_chunk84", "text": "aw: Conflicting Conceptions of Tort \n\n비교사법 제29권 4호(통권 제99호)\n248\nPreemption, 74 Brook L. Rev. 987 (2009).Sara Gerke, Boris Babic, Theodoros Evgeniou & I. Glenn Cohen, The need for a system view to regulate artificial intelligence/machine learning-based software as a medical device, 53 NPJ Digital Medicine 1 (2020).Sara Gerke, Timo Minssen & Glenn Cohen, Ethical and legal challenges of artificial intelligence-driven healthcare, in Artificial intelligence in Healthcare 314 (Adam Bohr & Kaveh Memarzadeh eds., 2020)..Scott J. Schweikart, Who Will Be Liable for Medical Malpractice in the Future? How the Use of Artificial Intelligence in Medicine Will Shape Medical Tort Law?, 22 Minn. J. L., Sci. & Tech. 1 (2021).Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, Regulatory resp", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 84}}
{"id": "doc1_chunk85", "text": " Tech. 1 (2021).Timo Minssen, Sara Gerke, Mateo Aboy, Nicholson Price & Glenn Cohen, Regulatory responses to medical machine learning, 7 J. L.& Biosciences 1 (2020)Timothy Hall, Reimagining the Learned Intermediary Rule for the New Pharmaceutical Marketplace, 35 Seton Hall L. Rev. (2005).W. Nicholson II Price, Black-Box Medicine, 28 Harv. J. L. & Tech. 419, 421 (2015); W. Nicholson Price II, Medical AI and Contextual Bias, 33 Harv. J. L. & Tech. 65 (2019).W. Nicholson Price II, Medical Malpractice and Blackbox Medicine, in Big Data, Health Law, and Bioethics (I. Glenn Cohen et al., eds., 2017).W. Nicholson Price II, Potential LIability for Physicians Using Artificial Intelligence, 322 JAMA 1765 (2019).W. Nicholson Price II, Regulating Black-Box Medicine, 116 Mich. L. Rev. 421 (2017).W. Nic", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 85}}
{"id": "doc1_chunk86", "text": "765 (2019).W. Nicholson Price II, Regulating Black-Box Medicine, 116 Mich. L. Rev. 421 (2017).W. Nicholson Price II, Sara Gerke & I. Glenn Cohen, How Much Can Potential Jurors Tell Us About Liability for Medical Artificial Intelligence?, 62 J. Nuclear Med. 15 (2021).W. Nicholson Price II. Artificial Intelligence in Health Care: Applications and Legal Implications, 14 The SciTech Lawyer 1 (2017).Ziad Obermeyer et al., Dissecting racial bias in an algorithm used to manage the health of populations, 366 Science 447 (2019). [기타자료]Machine learning (AI) accurately predicts cardiac arrest risk, BMJ (May 17, 2021), https://www.bmj.com/company/newsroom/machine-learning-ai-accurately-predicts-cardiac-arrest-risk/.Boris Babic & Sara Gerke, Explaining Medical AI is Easier Said than Done, Stat news (Ju", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 86}}
{"id": "doc1_chunk87", "text": "arrest-risk/.Boris Babic & Sara Gerke, Explaining Medical AI is Easier Said than Done, Stat news (Jul. 21, 2021),https://www.statnews.com/2021/07/21/explainable-medical-ai-easier-said-than-done.\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 249\nComm. on Legal Affairs, Eur. Union Parliament, Rep. with Recommendations to the Comm’n on Civ. L. Rules on Robotics (2017), https://www.europarl.europa.eu/committees/en/report-with-recommendations-to-the-commi/product-details/20170202CDT01121.Eliza Strickland, Hospitals Roll out AI systems to Keep Patients From Dying of Sepsis, IEEE Spectrum (Oct. 19, 2018).Eur. Comm’n, Directorate-General for Justice and Consumers, Liability for Artificial Intelligence and Other Emerging Digital Technologies (2019), https://data.europa.eu/doi/10.2838/573689.", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 87}}
{"id": "doc1_chunk88", "text": "elligence and Other Emerging Digital Technologies (2019), https://data.europa.eu/doi/10.2838/573689.IMDRF AIMD Working Group, Machine Learning-enabled Medical Devices—A Subset of Artificial Intelligence-enabled Medical Devices: Key Terms and Definitions (2021).IMDRF SaMD Working Group, Software as a Medical Device\": Possible Framework for Risk Categorization and Corresponding Considerations (2014).IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Application of Quality Management System (2015).IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Clinical Evaluation (2017).IMDRF SaMD Working Group, Software as a Medical Device (SaMD): Key Definitions (2013).Jessica Hamzelou, AI system is better than human doctors at predicting breast cancer, New Scientist (Jan. 1, 202", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 88}}
{"id": "doc1_chunk89", "text": "elou, AI system is better than human doctors at predicting breast cancer, New Scientist (Jan. 1, 2020). Jessica Kent, One Third of Orgs Use A.I. in Med. Imaging, Health IT Analytics (Jan. 28, 2020), https://healthitanalytics.com/news/one-third-of-orgs-use-artificial-intelligence-in-medical-imaging.Liat Clark, Vinod Khosla: Machines will replace 80 percent of doctors, Wired (Apr. 9, 2012), https://www.wired.co.uk/article/doctors-replaced-with-machines.U.S. Food and Drug Admin., Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device Action Plan (2021), https://www.fda.gov/media/145022/download.U.S. Food and Drug Admin., General Wellness: Policy for Low Risk Devices, Guidance for Industry and Food and Drug Administration Staff (2019), https://www.fda.gov/media/906", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 89}}
{"id": "doc1_chunk90", "text": ", Guidance for Industry and Food and Drug Administration Staff (2019), https://www.fda.gov/media/90652/download.U.S. Food and Drug Admin., Guidance on Software as a Medical Device(SAMD): Clinical Evaluation (2017), https://www.fda.gov/media/100714/download.U.S. Food and Drug Admin., How to Study and Market Your Device, https://www.fda.gov/medical-devices/device-advice-comprehensive-regulatory-assistance/how-study-and-market-your-device.U.S. Food and Drug Admin., Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning Based Software as a Medical Device (SaMD) (2019), https://www.fda.gov/media/122535/download.U.S. Food and Drug Admin., Proposed Regulatory Framework for Modifications to AI/ML-Based Software as a Medical Device (SaMD) (2019), https://www.fda", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 90}}
{"id": "doc1_chunk91", "text": "amework for Modifications to AI/ML-Based Software as a Medical Device (SaMD) (2019), https://www.fda.gov/files/medical%20devices/published\n\n비교사법 제29권 4호(통권 제99호)\n250\n/US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf.U.S. Food and Drug Admin., Software as a Medical Device, https://www.fda.gov/medical-devices/digital-health/software-medical-device-samd.U.S. Food and Drug Admin., Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices, https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices.Medtronic, Inc. v. Lohr, 518 U.S. 470, 471 (1996).Riegel v. Medtronic, Inc., 552 U.S. 312 (2008).Tesauro v Perrige, 650 A2d, 1079 (Pa Super Ct 1994).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 ", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 91}}
{"id": "doc1_chunk92", "text": "2 U.S. 312 (2008).Tesauro v Perrige, 650 A2d, 1079 (Pa Super Ct 1994).\n\n의료 인공지능의 활용을 둘러싼 법적 과제: 규제의 진화 및 책임의 배분을 중심으로|박혜진|\n 251\n[Abstract]Legal Challenges in Deploying Artificial Intelligence in Medicine: Focusing on the Evolution of Regulation and the Distribution of Liability129) Park, Hai Jin*Technological advances in artificial intelligence (AI) are transforming health care by assisting healthcare providers and improving patient care. However, AI medical devices may err and adversely affect the physician’s decision-making, resulting in patient harm. Therefore, regulating AI medical devices and allocating liability arising from algorithm inaccuracy is critical for patient safety and innovation in clinical care. This paper provides an overview of the three evolutional stages in regulatin", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 92}}
{"id": "doc1_chunk93", "text": "ation in clinical care. This paper provides an overview of the three evolutional stages in regulating AI medical devices and highlights the remaining issues for the regulatory agencies to be addressed. Moreover, this study considers multiple stakeholders beyond clinicians and alternative policy options in its liability analysis and identifies questions that call for deeper investigation and discussion in the future. ❙Key Words❙medical artificial intelligence, artificial intelligence medical device, medical device regulation, medical malpractice, informed consent, duty to explain, product liability\n*Associate professor, Hanyang University Law School", "meta": {"source_path": "data/raw/KCI_FI002904304(Medical AI regulation).pdf", "chunk_index": 93}}
